{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "@model_wrapper\n",
    "class ModelSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn.LayerChoice([\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            DepthwiseSeparableConv(32, 64)\n",
    "        ])\n",
    "        # ValueChoice is used to select a dropout rate.\n",
    "        # ValueChoice can be used as parameter of modules wrapped in `nni.retiarii.nn.pytorch`\n",
    "        # or customized modules wrapped with `@basic_unit`.\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nn.ValueChoice([64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "    \n",
    "    \n",
    "model_space = ModelSpace()\n",
    "model_space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "search_strategy = strategy.Random(dedup=True)  # dedup=False if deduplication is not wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_epoch(model, device, train_loader, optimizer, epoch):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test_epoch(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          correct, len(test_loader.dataset), accuracy))\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_model(model_cls):\n",
    "    # \"model_cls\" is a class, need to instantiate\n",
    "    model = model_cls()\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    transf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_loader = DataLoader(MNIST('data/mnist', download=True, transform=transf), batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(MNIST('data/mnist', download=True, train=False, transform=transf), batch_size=64)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        # train the model for one epoch\n",
    "        train_epoch(model, device, train_loader, optimizer, epoch)\n",
    "        # test the model for one epoch\n",
    "        accuracy = test_epoch(model, device, test_loader)\n",
    "        # call report intermediate result. Result can be float or dict\n",
    "        nni.report_intermediate_result(accuracy)\n",
    "\n",
    "    # report final test result\n",
    "    nni.report_final_result(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "evaluator = FunctionalEvaluator(evaluate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 24   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the experiment\n",
    "from nni.experiment import Experiment\n",
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
