{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P4 7680.0\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from eval_sgld import LightningEvalSearchSGLD, SingleImageDataset\n",
    "from space import DARTS_UNet\n",
    "from darts.common_utils import *\n",
    "from darts.phantom import generate_phantom\n",
    "\n",
    "from nni import trace\n",
    "\n",
    "import nni.retiarii.serializer as serializer\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.strategy import DARTS as DartsStrategy\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightning no search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                       in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "num_iter=1\n",
    "total_iterations = 25000\n",
    "\n",
    "resolution = 6\n",
    "max_depth = resolution - 1\n",
    "phantom = generate_phantom(resolution=resolution)\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEvalSearchSGLD(\n",
    "                phantom=phantom, \n",
    "                num_iter=num_iter,\n",
    "                lr=0.01, # note a smaller learning rate affecs the SGLD, so overfitting happens FASTER at LOWER learning rates (start with 0.01)\n",
    "                noise_type='gaussian', \n",
    "                noise_factor=0.09,\n",
    "                resolution=resolution,\n",
    "                burnin_iter=350,\n",
    "                model_cls=model\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            # callbacks=[module.checkpoint_callback],\n",
    "            max_epochs=total_iterations\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oneshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1\n",
    "total_iterations = 25000\n",
    "\n",
    "resolution = 6\n",
    "max_depth = resolution - 1\n",
    "phantom = generate_phantom(resolution=resolution)\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEvalSearchSGLD(\n",
    "                phantom=phantom, \n",
    "                num_iter=num_iter,\n",
    "                lr=0.01, # note a smaller learning rate affecs the SGLD, so overfitting happens FASTER at LOWER learning rates (start with 0.01)\n",
    "                noise_type='gaussian', \n",
    "                noise_factor=0.09,\n",
    "                resolution=resolution,\n",
    "                burnin_iter=1800\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            # callbacks=[module.checkpoint_callback],\n",
    "            max_epochs=total_iterations/(2*num_iter),\n",
    "                # it's either in my code or the lighting but total iterations will end up being twice that of the input value to max_epochs\n",
    "                # that means that if you want 5000 iterations, you need to set max_epochs=2500\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = DARTS_UNet(depth=3)\n",
    "\n",
    "# Select the Search Strategy\n",
    "strategy = DartsStrategy()\n",
    "\n",
    "# fast_dev_run=False\n",
    "\n",
    "config = RetiariiExeConfig(execution_engine='oneshot')\n",
    "experiment = RetiariiExperiment(model_space, evaluator=lightning, strategy=strategy)\n",
    "experiment.run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop experiment and clear cache\n",
    "experiment.stop()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exported_arch = experiment.export_top_models()\n",
    "\n",
    "exported_arch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1\n",
    "total_iterations = 1200\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEvalSearch(\n",
    "                phantom=phantom, \n",
    "                buffer_size=100,\n",
    "                num_iter=num_iter,\n",
    "                lr=0.01, \n",
    "                noise_type='gaussian', \n",
    "                noise_factor=0.075, \n",
    "                resolution=resolution,\n",
    "                buffer_no_lr_schuler=600,\n",
    "                patience=100,\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            # callbacks=[early_stop_callback],\n",
    "            max_epochs=total_iterations/(2*num_iter),\n",
    "                # it's either in my code or the lighting but total iterations will end up being twice that of the input value to max_epochs\n",
    "                # that means that if you want 5000 iterations, you need to set max_epochs=2500\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = DARTS_UNet()\n",
    "\n",
    "# Select a Search Strategy\n",
    "search_strategy = DartsStrategy()\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "\n",
    "serializer.pickle_size_limit = 1024 * 1024 * 100 # 100MB\n",
    "\n",
    "exp_config.max_trial_number = 4   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exported_arch = experiment.export_top_models()\n",
    "\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()\n",
    "\n",
    "# clear the cuda cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
