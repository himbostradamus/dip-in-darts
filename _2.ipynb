{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii import model_wrapper\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as skimage_psnr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# non search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTest(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, hidden_channels=16):\n",
    "        super(ModelTest, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act1 = nn.LeakyReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.bn1(self.conv1(x)))\n",
    "        x = self.act2(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "def add_noise(img, noise_factor=0.5):\n",
    "    \"\"\"Add random noise to an image.\"\"\"\n",
    "    noise = torch.randn_like(img) * noise_factor\n",
    "    noisy_img = img + noise\n",
    "    return torch.clamp(noisy_img, 0., 1.)\n",
    "\n",
    "def deep_image_prior_denoising(model, noisy_img, device, optimizer, iterations=3000):\n",
    "    model.train()\n",
    "    for iteration in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(torch.randn(noisy_img.shape).to(device))\n",
    "        loss = nn.MSELoss()(output, noisy_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % 1000 == 0:\n",
    "            print('Iteration: {}\\tLoss: {:.6f}'.format(iteration, loss.item()))\n",
    "\n",
    "\n",
    "    return output\n",
    "\n",
    "def denoise_image():\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load and preprocess the noisy image\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    \n",
    "    # Let's use the first image from the dataset\n",
    "    img, _ = dataset[0]\n",
    "    noisy_img = add_noise(img).unsqueeze(0).to(device)  # Add noise and batch dimension\n",
    "\n",
    "    # Initialize model and optimizer\n",
    "    model = ModelTest(in_channels=3, out_channels=3).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # Denoise the image using Deep Image Prior\n",
    "    denoised_img = deep_image_prior_denoising(model, noisy_img, device, optimizer)\n",
    "\n",
    "    # Visualize the noisy and denoised images\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "    plt.title('Original Image')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(np.transpose(noisy_img[0].cpu().numpy(), (1, 2, 0)))\n",
    "    plt.title('Noisy Image')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(np.transpose(denoised_img[0].detach().cpu().numpy(), (1, 2, 0)))\n",
    "    plt.title('Denoised Image')\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "# denoise_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.downsample1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "\n",
    "# self.upsample = nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True)\n",
    "# self.upsample = nn.Upsample(scale_factor=2,mode='bicubic', align_corners=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expanded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_channels = 64\n",
    "        ks = 3 # nn.ValueChoice([3, 7])\n",
    "        dl = 1 # nn.ValueChoice([3, 4])\n",
    "        pd = (ks-1)*dl//2\n",
    "\n",
    "        # Conv layer in\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act2 = nn.Sigmoid()\n",
    "\n",
    "        self.first = nn.Sequential(\n",
    "            self.conv1,self.bn1,self.act1,\n",
    "            self.conv2, self.bn2,self.act2\n",
    "        )\n",
    "\n",
    "        # Encoder 1\n",
    "        self.downsample1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, hidden_channels*2, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(hidden_channels*2, hidden_channels*2, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act4 = nn.Sigmoid()\n",
    "\n",
    "        self.Encoder1 = nn.Sequential(\n",
    "            self.downsample1,\n",
    "            self.conv3,self.bn3,self.act3,\n",
    "            self.conv4,self.bn4,self.act4\n",
    "        )\n",
    "\n",
    "\n",
    "        # Decoder 1\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "\n",
    "        self.conv5 = nn.Conv2d(hidden_channels*3, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act5 = nn.ReLU(inplace=True)\n",
    "        self.conv6 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn6 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act6 = nn.Sigmoid()\n",
    "\n",
    "        self.Decoder1 = nn.Sequential(\n",
    "            self.conv5, self.bn5, self.act5,\n",
    "            self.conv6, self.bn6, self.act6\n",
    "            )\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(hidden_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "    \n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "    \n",
    "    def upsample_and_crop(self, input, skip, upsample, decode):\n",
    "        upsampled = upsample(input)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return decode(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "    def print_info(self, layer_name, tensor):\n",
    "        separator = \"-\" * 50\n",
    "        if layer_name == \"Input\":\n",
    "            print(separator)\n",
    "            print(separator)\n",
    "        if layer_name == \"Output\":\n",
    "            print(f\"Layer: {layer_name} -- Conv Layer Out\")\n",
    "            print(f\"Output Shape: {tensor.shape}\")\n",
    "            print(separator)\n",
    "            print(separator)\n",
    "        else:        \n",
    "            print(f\"Layer: {layer_name}\")\n",
    "            print(f\"Output Shape: {tensor.shape}\")\n",
    "            print(separator)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.print_info(\"Input\", x)\n",
    "\n",
    "        x = self.first(x)\n",
    "        self.print_info(\"Conv layer in\", x)\n",
    "\n",
    "        x1 = self.Encoder1(x)\n",
    "        self.print_info(\"Encoder 1\", x1)\n",
    "\n",
    "        x2 = self.upsample_and_crop(\n",
    "            x1, # input\n",
    "            x, # skip\n",
    "            self.upsample1, # upsample \n",
    "            self.Decoder1 # decode\n",
    "            )\n",
    "        self.print_info(\"Decoder 1\", x2)\n",
    "\n",
    "        x3 = self.out(x2)\n",
    "        self.print_info(\"Output\", x3)\n",
    "\n",
    "        return x3\n",
    "\n",
    "x = torch.randn(1, 3, 64, 64)\n",
    "model = Test()\n",
    "output = model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# expanded search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model_wrapper\n",
    "class SearchSpace(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_channels = 64\n",
    "        ks = nn.ValueChoice([1, 3], label=\"Kernel Size\")\n",
    "        dl = nn.ValueChoice([1, 3, 5], label=\"Dilation Rate\")\n",
    "        pd = (ks-1)*dl//2\n",
    "\n",
    "        activations = OrderedDict([\n",
    "            (\"RelU\", nn.ReLU(inplace=True)),\n",
    "            (\"LeakyRelU\", nn.LeakyReLU(inplace=True)),\n",
    "            (\"Sigmoid\", nn.Sigmoid()),\n",
    "            (\"Selu\", nn.SELU(inplace=True)),\n",
    "            (\"PreLU\", nn.PReLU()),\n",
    "            (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "        ])\n",
    "\n",
    "        downsample = OrderedDict([\n",
    "            (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "        ])\n",
    "\n",
    "        upsample = OrderedDict([\n",
    "            (\"Nearest\", nn.Upsample(scale_factor=2,mode='nearest')),\n",
    "            (\"Bilinear\", nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True)),\n",
    "            (\"Bicubic\", nn.Upsample(scale_factor=2,mode='bicubic', align_corners=True))\n",
    "        ])\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.layer1_name = \"1 - Conv layer in\"\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act1 = nn.LayerChoice(activations, label=f\"{self.layer1_name}: Activation Function 1\")\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act2 = nn.LayerChoice(activations, label=f\"{self.layer1_name}: Activation Function 2\")\n",
    "\n",
    "        self.first = nn.Sequential(\n",
    "            self.conv1,self.bn1,self.act1,\n",
    "            self.conv2, self.bn2,self.act2\n",
    "        )\n",
    "\n",
    "        # Encoder 1\n",
    "        self.layer2_name = \"2 - Encoder 1\"\n",
    "        self.downsample1 = nn.LayerChoice(downsample,label=\"First Pooling Technique\")\n",
    "\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, hidden_channels*2, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act3 = nn.LayerChoice(activations, label=f\"{self.layer2_name}: Activation Function 1\")\n",
    "        self.conv4 = nn.Conv2d(hidden_channels*2, hidden_channels*2, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act4 = nn.LayerChoice(activations, label=f\"{self.layer2_name}: Activation Function 2\")\n",
    "\n",
    "        self.Encoder1 = nn.Sequential(\n",
    "            self.downsample1,\n",
    "            self.conv3,self.bn3,self.act3,\n",
    "            self.conv4,self.bn4,self.act4\n",
    "        )\n",
    "\n",
    "        # Decoder 1\n",
    "        self.layer3_name = \"3 - Decoder 1\"\n",
    "        self.upsample1 = nn.LayerChoice(upsample, label=\"First Upsample Technique\")\n",
    "\n",
    "        self.conv5 = nn.Conv2d(hidden_channels*3, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn5 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act5 = nn.LayerChoice(activations, label=f\"{self.layer3_name}: Activation Function 1\")\n",
    "        self.conv6 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn6 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act6 = nn.LayerChoice(activations, label=f\"{self.layer3_name}: Activation Function 2\")\n",
    "\n",
    "        self.Decoder1 = nn.Sequential(\n",
    "            self.conv5, self.bn5, self.act5,\n",
    "            self.conv6, self.bn6, self.act6\n",
    "            )\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(hidden_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "    \n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "    \n",
    "    def upsample_and_crop(self, input, skip, upsample, decode):\n",
    "        upsampled = upsample(input)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return decode(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "    def print_info(self, layer_name, tensor):\n",
    "        separator = \"-\" * 50\n",
    "        if layer_name == \"Input\":\n",
    "            print(separator)\n",
    "            print(separator)\n",
    "        if layer_name == \"Output\":\n",
    "            print(f\"Layer: {layer_name} -- Conv Layer Out\")\n",
    "            print(f\"Output Shape: {tensor.shape}\")\n",
    "            print(separator)\n",
    "            print(separator)\n",
    "        else:        \n",
    "            print(f\"Layer: {layer_name}\")\n",
    "            print(f\"Output Shape: {tensor.shape}\")\n",
    "            print(separator)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.print_info(\"Input\", x)\n",
    "\n",
    "        x = self.first(x)\n",
    "        self.print_info(\"Conv layer in\", x)\n",
    "\n",
    "        x1 = self.Encoder1(x)\n",
    "        self.print_info(\"Encoder 1\", x1)\n",
    "\n",
    "        x2 = self.upsample_and_crop(\n",
    "            x1, # input\n",
    "            x, # skip\n",
    "            self.upsample1, # upsample \n",
    "            self.Decoder1 # decode\n",
    "            )\n",
    "        self.print_info(\"Decoder 1\", x2)\n",
    "\n",
    "        x3 = self.out(x2)\n",
    "        self.print_info(\"Output\", x3)\n",
    "\n",
    "        return x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(image_true, image_test):\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    if torch.is_tensor(image_true):\n",
    "        image_true = image_true.detach().cpu().numpy()\n",
    "    if torch.is_tensor(image_test):\n",
    "        image_test = image_test.detach().cpu().numpy()\n",
    "    return skimage_psnr(image_true, image_test)\n",
    "\n",
    "def deep_image_prior_denoising(model, noisy_img, clean_img, device, optimizer, iterations=3000):\n",
    "    model.train()\n",
    "    for iteration in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(torch.randn(noisy_img.shape).to(device))\n",
    "        loss = nn.MSELoss()(output, noisy_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % 1000 == 0:\n",
    "            # Calculate PSNR\n",
    "            with torch.no_grad():\n",
    "                denoised_output = model(noisy_img)\n",
    "                psnr_value = psnr(clean_img, denoised_output)\n",
    "            print('Iteration: {}\\tLoss: {:.6f}\\tPSNR: {:.6f} dB'.format(iteration, loss.item(), psnr_value))\n",
    "            nni.report_intermediate_result(psnr_value)\n",
    "    return output\n",
    "\n",
    "def evaluate_denoising(denoised_img, clean_img):\n",
    "    # We no longer need the model in an eval state or any forward pass here\n",
    "    # because the denoised image is already generated and passed to the function.\n",
    "    return psnr(clean_img, denoised_img)\n",
    "\n",
    "def main_evaluation(model_cls):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = model_cls().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    img, _ = dataset[0]  # Original clean image\n",
    "    noisy_img = add_noise(img).unsqueeze(0).to(device)  # Noisy version of image\n",
    "\n",
    "    # Denoise the image for a set number of iterations\n",
    "    denoised_img = deep_image_prior_denoising(model, noisy_img, img.unsqueeze(0).to(device), device, optimizer)\n",
    "\n",
    "    # Evaluate the PSNR of the denoised image\n",
    "    psnr_value = evaluate_denoising(denoised_img, img.unsqueeze(0).to(device))\n",
    "    print('PSNR: {:.6f} dB'.format(psnr_value))\n",
    "\n",
    "    # Report final PSNR to NNI\n",
    "    nni.report_final_result(psnr_value.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 24   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "@model_wrapper\n",
    "class ModelSpace(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        hidden_channels = 16\n",
    "        ks = nn.ValueChoice([3, 7])\n",
    "        dl = nn.ValueChoice([3, 4])\n",
    "        pd = (ks-1)*dl//2\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, hidden_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn1 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act1 = nn.LayerChoice([\n",
    "                        nn.ReLU(inplace=True),\n",
    "                        # nn.LeakyReLU(inplace=True),\n",
    "                        # nn.PReLU(),\n",
    "                        # nn.SELU(),\n",
    "                        # nn.SiLU(inplace=True),\n",
    "                    ])\n",
    "        self.conv2 = nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(hidden_channels)\n",
    "        self.act2 = nn.LayerChoice([\n",
    "                        nn.Sigmoid(),\n",
    "                    ])\n",
    "        \n",
    "        self.downsample = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, hidden_channels*2, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn3 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act3 = nn.LayerChoice([\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    ])\n",
    "        self.conv4 = nn.Conv2d(hidden_channels*2, hidden_channels*2, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(hidden_channels*2)\n",
    "        self.act4 = nn.LayerChoice([\n",
    "                        nn.Sigmoid(),\n",
    "                    ])\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(hidden_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.act3 = nn.LayerChoice([\n",
    "                        nn.ReLU(inplace=True),\n",
    "                    ])\n",
    "        self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        self.bn4 = nn.BatchNorm2d(out_channels)\n",
    "        self.act4 = nn.LayerChoice([\n",
    "                        nn.Sigmoid(),\n",
    "                    ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "\n",
    "def psnr(image_true, image_test):\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    if torch.is_tensor(image_true):\n",
    "        image_true = image_true.detach().cpu().numpy()\n",
    "    if torch.is_tensor(image_test):\n",
    "        image_test = image_test.detach().cpu().numpy()\n",
    "    return skimage_psnr(image_true, image_test)\n",
    "\n",
    "def deep_image_prior_denoising(model, noisy_img, clean_img, device, optimizer, iterations=3000):\n",
    "    model.train()\n",
    "    for iteration in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(torch.randn(noisy_img.shape).to(device))\n",
    "        loss = nn.MSELoss()(output, noisy_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % 1000 == 0:\n",
    "            # Calculate PSNR\n",
    "            with torch.no_grad():\n",
    "                denoised_output = model(noisy_img)\n",
    "                psnr_value = psnr(clean_img, denoised_output)\n",
    "            print('Iteration: {}\\tLoss: {:.6f}\\tPSNR: {:.6f} dB'.format(iteration, loss.item(), psnr_value))\n",
    "            nni.report_intermediate_result(psnr_value)\n",
    "    return output\n",
    "\n",
    "def evaluate_denoising(denoised_img, clean_img):\n",
    "    # We no longer need the model in an eval state or any forward pass here\n",
    "    # because the denoised image is already generated and passed to the function.\n",
    "    return psnr(clean_img, denoised_img)\n",
    "\n",
    "def main_evaluation(model_cls):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = model_cls().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    img, _ = dataset[0]  # Original clean image\n",
    "    noisy_img = add_noise(img).unsqueeze(0).to(device)  # Noisy version of image\n",
    "\n",
    "    # Denoise the image for a set number of iterations\n",
    "    denoised_img = deep_image_prior_denoising(model, noisy_img, img.unsqueeze(0).to(device), device, optimizer)\n",
    "\n",
    "    # Evaluate the PSNR of the denoised image\n",
    "    psnr_value = evaluate_denoising(denoised_img, img.unsqueeze(0).to(device))\n",
    "    print('PSNR: {:.6f} dB'.format(psnr_value))\n",
    "\n",
    "    # Report final PSNR to NNI\n",
    "    nni.report_final_result(psnr_value.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = ModelSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 24   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
