{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Convolutions(nn.Module):\n",
    "    def __init__(self, conv, layer_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.LayerChoice(conv, label=f'{layer_name} - Step 2: Convolutions, Batchnorm and Activation')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, activation):\n",
    "        layers = [\n",
    "            (\"Conv2d\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            ),\n",
    "            (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl, groups=out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        return OrderedDict(layers)\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, downsamples, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = nn.LayerChoice(downsamples,label=f'{layer_name} - Step 1: Downsampling Technique')\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv_layer(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, upsamples, layer_name):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.upsample = nn.LayerChoice(upsamples, label=f\"{layer_name} - Step 0: Upsampling Technique\")\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(BaseBlock):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        network_depth = nn.ValueChoice([1, 2, 3, 4], label=\"Network Depth\")\n",
    "\n",
    "        ks = nn.ValueChoice([3, 5], label=\"Kernel Size\")\n",
    "        dl = nn.ValueChoice([1, 3], label=\"Dilation Rate\")\n",
    "        pd = (ks - 1) * dl // 2\n",
    "\n",
    "        activations = nn.LayerChoice(OrderedDict([\n",
    "            (\"RelU\", nn.ReLU(inplace=True)),\n",
    "            # (\"Sigmoid\", nn.Sigmoid()),\n",
    "            (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "        ]), label=\"Activation\")\n",
    "\n",
    "        downsamples = OrderedDict([\n",
    "            (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "        ])\n",
    "\n",
    "        upsamples = OrderedDict([\n",
    "            (\"Nearest\", nn.Upsample(scale_factor=2,mode='nearest')),\n",
    "            (\"Bilinear\", nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True))\n",
    "        ])\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.mid_channels = 64\n",
    "        self.first = Convolutions(self.get_conv_ordered_dict(in_channels, self.mid_channels, 1, 0, 1, nn.Sigmoid()), \"First Conv Layer\")\n",
    "\n",
    "        # For Encoders:\n",
    "        encoder_block = lambda index: EncoderBlock(64*(2**index), 64*(2**(index+1)), ks, pd, dl, activations, downsamples, f\"Encoder {index+1}\")\n",
    "        self.encoders = nn.Repeat(encoder_block, network_depth)\n",
    "\n",
    "        # For Decoders:\n",
    "        decoder_block = lambda index: DecoderBlock(64*(2**(index))*3, 64*(2**index), ks, pd, dl, activations, upsamples, f\"Decoder {index+1}\")\n",
    "        self.decoders = nn.Repeat(decoder_block, network_depth)\n",
    "        self.decoders = self.decoders[::-1]\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(self.mid_channels, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logger.info(\"Input: %s\", x.size())\n",
    "        \n",
    "        # Variables to store intermediate values\n",
    "        encoder_outputs = []\n",
    "\n",
    "        # Start with the first conv layer\n",
    "        x = self.first(x)\n",
    "        encoder_outputs.append(x)\n",
    "        logger.info(f\"Initial Conv Layer: %s\", x.size())\n",
    "\n",
    "        # Encoder pass\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            logger.info(f\"Encoder {i+1}: %s\", x.size())\n",
    "\n",
    "        # Decoder pass\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            x = decoder(x, encoder_outputs[-(i+2)])\n",
    "            logger.info(f\"Decoder {len(self.decoders) - i}: %s\", x.size())\n",
    "\n",
    "        x = self.out(x)\n",
    "        logger.info(\"Output: %s\", x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from darts.eval import main_evaluation\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = [\n",
    "    strategy.Random(dedup=True), # multi\n",
    "    strategy.RegularizedEvolution(dedup=True), # multi\n",
    "    strategy.TPE(), # multi\n",
    "    strategy.DARTS() # One-Shot\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "search_strategy = strategy.DARTS()\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "# exp_config.training_service.engine = 'oneshot' # only if using darts\n",
    "\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.nas.strategy import DARTS as DartsStrategy\n",
    "# from nni.nas.experiment import RetiariiExperiment\n",
    "from nni.nas.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.nas.evaluator import FunctionalEvaluator\n",
    "from darts.eval import main_evaluation\n",
    "from nni.experiment import Experiment\n",
    "\n",
    "\n",
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "search_strategy = DartsStrategy()\n",
    "\n",
    "# experiment\n",
    "# exp = RetiariiExperiment(model_space, evaluator, None, search_strategy)\n",
    "exp = RetiariiExperiment(base_model=model_space, evaluator=evaluator, strategy=search_strategy)\n",
    "\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "# exp_config.experiment_name = 'mnist_search'\n",
    "# exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "# exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "# # exp_config.training_service.engine = 'oneshot' # only if using darts\n",
    "\n",
    "\n",
    "# exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)\n",
    "\n",
    "exported_arch = experiment.export_top_models(formatter='dict')[0:10]\n",
    "\n",
    "exported_arch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
