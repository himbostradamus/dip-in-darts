{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "from torch import cuda, optim, tensor, zeros_like\n",
    "from torch import device as torch_device\n",
    "from torch.nn import L1Loss, MSELoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.phantom import generate_phantom, phantom_to_torch\n",
    "from darts.noises import add_selected_noise\n",
    "\n",
    "\n",
    "class EarlyStop():\n",
    "    def __init__(self, size, patience):\n",
    "        self.patience = patience\n",
    "        self.wait_count = 0\n",
    "        self.best_score = float('inf')\n",
    "        self.best_epoch = 0\n",
    "        self.img_collection = []\n",
    "        self.stop = False\n",
    "        self.size = size\n",
    "\n",
    "    def check_stop(self, current, cur_epoch):\n",
    "      #stop when variance doesn't decrease for consecutive P(patience) times\n",
    "        if current < self.best_score:\n",
    "            self.best_score = current\n",
    "            self.best_epoch = cur_epoch\n",
    "            self.wait_count = 0\n",
    "            should_stop = False\n",
    "        else:\n",
    "            self.wait_count += 1\n",
    "            should_stop = self.wait_count >= self.patience\n",
    "        return should_stop\n",
    "\n",
    "    def update_img_collection(self, cur_img):\n",
    "        self.img_collection.append(cur_img)\n",
    "        if len(self.img_collection) > self.size:\n",
    "            self.img_collection.pop(0)\n",
    "\n",
    "    def get_img_collection(self):\n",
    "        return self.img_collection\n",
    "\n",
    "def MSE(x1, x2):\n",
    "    return ((x1 - x2) ** 2).sum() / x1.size\n",
    "\n",
    "def MAE(x1, x2):\n",
    "    return (np.abs(x1 - x2)).sum() / x1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # 64 x 8 x 8\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1), # 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),  # 3 x 64 x 64\n",
    "            nn.Sigmoid()  # To bring the output values between 0 and 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = EncoderDecoder()\n",
    "input_tensor = torch.randn(1, 3, 64, 64)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # torch.Size([1, 3, 64, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_space(Space):\n",
    "    dtype = cuda.FloatTensor\n",
    "    buffer_size = 100\n",
    "    patience = 1000\n",
    "    lr = 0.01\n",
    "    num_iter = 2\n",
    "\n",
    "    device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "\n",
    "    noise_type = 'gaussian'\n",
    "    img_np = generate_phantom(resolution=6)\n",
    "    img = phantom_to_torch(img_np)\n",
    "    img_noisy = add_selected_noise(img, noise_type=noise_type).to(device)\n",
    "    img_noisy_np = torch_to_np(img_noisy.squeeze())\n",
    "\n",
    "    net_input = get_noise(input_depth=3, spatial_size=img.size()[3], noise_type=noise_type).to(device)\n",
    "\n",
    "\n",
    "    # Add synthetic noise\n",
    "    net = Space.to(device)\n",
    "    net = net.type(dtype)\n",
    "\n",
    "    # Loss\n",
    "    criterion = MSELoss().type(dtype).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    p = get_params('net', net, net_input)  # network parameters to be optimized\n",
    "    optimizer = optim.Adam(p, lr=lr)\n",
    "\n",
    "    # Optimize\n",
    "\n",
    "    # reg_noise_std = 1./30. \n",
    "    reg_noise_std = tensor(1./30.).type(dtype).to(device)\n",
    "    show_every = 1\n",
    "    loss_history = []\n",
    "    psnr_history = []\n",
    "    ssim_history = []\n",
    "    variance_history = []\n",
    "    x_axis = []\n",
    "    earlystop = EarlyStop(size=buffer_size,patience=patience)\n",
    "    def closure(iterator):\n",
    "        #DIP\n",
    "        net_input_perturbed = net_input + zeros_like(net_input).normal_(std=reg_noise_std)\n",
    "        r_img_torch = net(net_input_perturbed)\n",
    "        total_loss = criterion(r_img_torch, img_noisy)\n",
    "        total_loss.backward()\n",
    "        loss_history.append(total_loss.item())\n",
    "        if iterator % show_every == 0:\n",
    "            # evaluate recovered image (PSNR, SSIM)\n",
    "            r_img_np = torch_to_np(r_img_torch)\n",
    "            psnr = skimage.metrics.peak_signal_noise_ratio(img_np, r_img_np)\n",
    "            temp_img_np = np.transpose(img_np,(1,2,0))\n",
    "            temp_r_img_np = np.transpose(r_img_np,(1,2,0))\n",
    "            data_range = temp_img_np.max() - temp_img_np.min()\n",
    "            ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=True, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "            psnr_history.append(psnr)\n",
    "            ssim_history.append(ssim)\n",
    "\n",
    "            #variance hisotry\n",
    "            r_img_np = r_img_np.reshape(-1)\n",
    "            earlystop.update_img_collection(r_img_np)\n",
    "            img_collection = earlystop.get_img_collection()\n",
    "            if len(img_collection) == buffer_size:\n",
    "                ave_img = np.mean(img_collection,axis = 0)\n",
    "                variance = []\n",
    "                for tmp in img_collection:\n",
    "                    variance.append(MSE(ave_img, tmp))\n",
    "                cur_var = np.mean(variance)\n",
    "                cur_epoch = iterator\n",
    "                variance_history.append(cur_var)\n",
    "                x_axis.append(cur_epoch)\n",
    "                if earlystop.stop == False:\n",
    "                    earlystop.stop = earlystop.check_stop(cur_var, cur_epoch)\n",
    "        return total_loss\n",
    "        \n",
    "    for iterator in range(num_iter):\n",
    "        optimizer.zero_grad()\n",
    "        closure(iterator)\n",
    "        optimizer.step()\n",
    "\n",
    "model = EncoderDecoder()\n",
    "test_space(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = cuda.FloatTensor\n",
    "buffer_size = 100\n",
    "patience = 1000\n",
    "lr = 0.01\n",
    "num_iter = 3000\n",
    "\n",
    "device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_type = 'gaussian'\n",
    "img_np = generate_phantom(resolution=6)\n",
    "img = phantom_to_torch(img_np)\n",
    "img_np = img.squeeze().numpy()\n",
    "img_noisy = add_selected_noise(img, noise_type=noise_type).to(device)\n",
    "img_noisy_np = torch_to_np(img_noisy.squeeze())\n",
    "img_noisy_np = phantom_to_torch(img_noisy_np).squeeze().numpy()\n",
    "\n",
    "net_input = get_noise(input_depth=3, spatial_size=img.size()[3], noise_type=noise_type).to(device)\n",
    "\n",
    "print(f'img_np.shape: {img_np.shape}')\n",
    "print(f'img shape: {img.shape}')\n",
    "print(f'img_noisy_np.shape: {img_noisy_np.shape}')\n",
    "print(f'net_input shape: {net_input.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import cuda, optim, tensor, zeros_like\n",
    "from torch import device as torch_device\n",
    "from torch.nn import L1Loss, MSELoss\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.phantom import generate_phantom, phantom_to_torch\n",
    "from darts.noises import add_selected_noise\n",
    "\n",
    "class EarlyStop():\n",
    "    def __init__(self, size, patience):\n",
    "        self.patience = patience\n",
    "        self.wait_count = 0\n",
    "        self.best_score = float('inf')\n",
    "        self.best_epoch = 0\n",
    "        self.img_collection = []\n",
    "        self.stop = False\n",
    "        self.size = size\n",
    "\n",
    "    def check_stop(self, current, cur_epoch):\n",
    "      #stop when variance doesn't decrease for consecutive P(patience) times\n",
    "        if current < self.best_score:\n",
    "            self.best_score = current\n",
    "            self.best_epoch = cur_epoch\n",
    "            self.wait_count = 0\n",
    "            should_stop = False\n",
    "        else:\n",
    "            self.wait_count += 1\n",
    "            should_stop = self.wait_count >= self.patience\n",
    "        return should_stop\n",
    "\n",
    "    def update_img_collection(self, cur_img):\n",
    "        self.img_collection.append(cur_img)\n",
    "        if len(self.img_collection) > self.size:\n",
    "            self.img_collection.pop(0)\n",
    "\n",
    "    def get_img_collection(self):\n",
    "        return self.img_collection\n",
    "\n",
    "def MSE(x1, x2):\n",
    "    return ((x1 - x2) ** 2).sum() / x1.size\n",
    "\n",
    "def MAE(x1, x2):\n",
    "    return (np.abs(x1 - x2)).sum() / x1.size\n",
    "\n",
    "\n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1),  # 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1), # 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # 64 x 8 x 8\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1), # 32 x 16 x 16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1), # 16 x 32 x 32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=4, stride=2, padding=1),  # 3 x 64 x 64\n",
    "            nn.Sigmoid()  # To bring the output values between 0 and 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "model = EncoderDecoder()\n",
    "input_tensor = torch.randn(1, 3, 64, 64)\n",
    "output = model(input_tensor)\n",
    "print(output.shape)  # torch.Size([1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = cuda.FloatTensor\n",
    "buffer_size = 100\n",
    "patience = 1000\n",
    "lr = 0.0005\n",
    "num_iter = 3000\n",
    "resolution=8\n",
    "\n",
    "device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_type = 'gaussian'\n",
    "\n",
    "raw_img_np = generate_phantom(resolution=resolution) # 64x64 np array\n",
    "print(f'raw_img_np.shape: {raw_img_np.shape}')\n",
    "\n",
    "img_np = raw_img_np.reshape(1, raw_img_np.shape[0], raw_img_np.shape[1]) # 1x64x64 np array\n",
    "img_np = np.repeat(img_np, 3, axis=0) # 3x64x64 np array\n",
    "img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "print(f'img_np.shape: {img_np.shape}')\n",
    "\n",
    "img_torch = phantom_to_torch(raw_img_np).unsqueeze(0) # 1x3x64x64 torch tensor\n",
    "print(f'img_torch.shape: {img_torch.shape}')\n",
    "\n",
    "img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type,noise_factor=0.15) # 1x3x64x64 torch tensor\n",
    "print(f'img_torch_noisy.shape: {img_noisy_torch.shape}')\n",
    "\n",
    "img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 3x64x64 np array\n",
    "print(f'raw_img_noisy_np.shape: {img_noisy_np.shape}')\n",
    "\n",
    "raw_img_noisy_np = np.mean(img_noisy_np, axis=0) # 64x64 np array\n",
    "print(f'raw_img_noisy_np_reduced.shape: {raw_img_noisy_np.shape}')\n",
    "\n",
    "\n",
    "img_noisy_torch = img_noisy_torch.to(device)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "fig.suptitle('Clean and Noisy Image')\n",
    "ax1.imshow(raw_img_np, cmap='gray')\n",
    "ax2.imshow(raw_img_noisy_np, cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax2.axis('off')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "net_input = get_noise(input_depth=3, spatial_size=raw_img_np.shape[1], noise_type=noise_type).type(dtype).to(device)\n",
    "\n",
    "model = EncoderDecoder()\n",
    "\n",
    "# Add synthetic noise\n",
    "net = model.to(device)\n",
    "net = net.type(dtype)\n",
    "\n",
    "# Loss\n",
    "criterion = MSELoss().type(dtype).to(device)\n",
    "\n",
    "# Optimizer\n",
    "p = get_params('net', net, net_input)  # network parameters to be optimized\n",
    "optimizer = optim.Adam(p, lr=lr)\n",
    "\n",
    "# Optimize\n",
    "\n",
    "# reg_noise_std = 1./30. \n",
    "reg_noise_std = tensor(1./30.).type(dtype).to(device)\n",
    "show_every = 1\n",
    "loss_history = []\n",
    "psnr_history = []\n",
    "ssim_history = []\n",
    "variance_history = []\n",
    "x_axis = []\n",
    "earlystop = EarlyStop(size=buffer_size,patience=patience)\n",
    "def closure(iterator):\n",
    "    #DIP\n",
    "    net_input_perturbed = net_input + zeros_like(net_input).normal_(std=reg_noise_std)\n",
    "    r_img_torch = net(net_input_perturbed)\n",
    "    total_loss = criterion(r_img_torch, img_noisy_torch)\n",
    "    total_loss.backward()\n",
    "    loss_history.append(total_loss.item())\n",
    "    if iterator % show_every == 0:\n",
    "        # evaluate recovered image (PSNR, SSIM)\n",
    "        r_img_np = torch_to_np(r_img_torch)\n",
    "        psnr = skimage.metrics.peak_signal_noise_ratio(img_np, r_img_np)\n",
    "        temp_img_np = np.transpose(img_np,(1,2,0))\n",
    "        temp_r_img_np = np.transpose(r_img_np,(1,2,0))\n",
    "        data_range = temp_img_np.max() - temp_img_np.min()\n",
    "        ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=True, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "        psnr_history.append(psnr)\n",
    "        ssim_history.append(ssim)\n",
    "\n",
    "        #variance hisotry\n",
    "        r_img_np = r_img_np.reshape(-1)\n",
    "        earlystop.update_img_collection(r_img_np)\n",
    "        img_collection = earlystop.get_img_collection()\n",
    "        if len(img_collection) == buffer_size:\n",
    "            ave_img = np.mean(img_collection,axis = 0)\n",
    "            variance = []\n",
    "            for tmp in img_collection:\n",
    "                variance.append(MSE(ave_img, tmp))\n",
    "            cur_var = np.mean(variance)\n",
    "            cur_epoch = iterator\n",
    "            variance_history.append(cur_var)\n",
    "            x_axis.append(cur_epoch)\n",
    "            if earlystop.stop == False:\n",
    "                earlystop.stop = earlystop.check_stop(cur_var, cur_epoch)\n",
    "    return total_loss\n",
    "    \n",
    "for iterator in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    closure(iterator)\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iterator % show_every == 0:\n",
    "        r_img_np = torch_to_np(net(net_input))\n",
    "        plot_image_grid([np.clip(img_np, 0, 1), np.clip(r_img_np, 0, 1)], factor=1, nrow=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
