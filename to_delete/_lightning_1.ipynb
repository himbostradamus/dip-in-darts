{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import skimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nni\n",
    "import numpy as np\n",
    "import skimage\n",
    "import torch\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as skimage_psnr\n",
    "\n",
    "from torch import cuda, optim, tensor, zeros_like\n",
    "from torch import device as torch_device\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.early_stop import EarlyStop, MSE, MAE\n",
    "from darts.noises import add_selected_noise\n",
    "from darts.phantom import generate_phantom, phantom_to_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(resolution, noise_type, noise_factor, input_img_np=None):\n",
    "    \"\"\"\n",
    "    Generates an image, adds noise, and converts it to both numpy and torch tensors.\n",
    "\n",
    "    Args:\n",
    "    - resolution (int): Resolution for the phantom image.\n",
    "    - noise_type (str): Type of noise to add.\n",
    "    - noise_factor (float): Noise factor.\n",
    "    - input_img_np (numpy.ndarray, optional): Input raw image in numpy format. If not provided, a new image will be generated.\n",
    "\n",
    "    Returns:\n",
    "    - img_np (numpy.ndarray): Original image in numpy format.\n",
    "    - img_noisy_np (numpy.ndarray): Noisy image in numpy format.\n",
    "    - img_torch (torch.Tensor): Original image in torch tensor format.\n",
    "    - img_noisy_torch (torch.Tensor): Noisy image in torch tensor format.\n",
    "    \"\"\"\n",
    "    if input_img_np is None:\n",
    "        raw_img_np = generate_phantom(resolution=resolution) # 1x64x64 np array\n",
    "    else:\n",
    "        raw_img_np = input_img_np.copy()\n",
    "        \n",
    "    img_np = raw_img_np.copy() # 1x64x64 np array\n",
    "    img_torch = torch.tensor(raw_img_np, dtype=torch.float32).unsqueeze(0) # 1x1x64x64 torch tensor\n",
    "    img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type, noise_factor=noise_factor) # 1x1x64x64 torch tensor\n",
    "    img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 1x64x64 np array\n",
    "    \n",
    "    return img_np, img_noisy_np, img_torch, img_noisy_torch\n",
    "\n",
    "\n",
    "def main_evaluation_with_closure(model_cls):\n",
    "    device = torch_device('cuda' if cuda.is_available() else \"cpu\")\n",
    "    dtype = cuda.FloatTensor if cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "    buffer_size = 100\n",
    "    patience = 600\n",
    "    num_iter = 1200\n",
    "    show_every = 1\n",
    "    lr = 0.00005\n",
    "\n",
    "    reg_noise_std = tensor(1./30.).type(dtype).to(device)\n",
    "    noise_type = 'gaussian'\n",
    "    noise_factor = 0.1\n",
    "    resolution= 6\n",
    "    n_channels = 1\n",
    "\n",
    "    img_np, _, _, img_noisy_torch = preprocess_image(resolution, noise_type, noise_factor)\n",
    "    img_noisy_torch = img_noisy_torch.to(device)\n",
    "    net_input = get_noise(input_depth=1, spatial_size=img_np.shape[1], noise_type=noise_type).type(dtype).to(device)\n",
    "\n",
    "    # Add synthetic noise\n",
    "    net = model_cls().to(device)\n",
    "    net = net.type(dtype)\n",
    "\n",
    "    # Loss\n",
    "    criterion = nn.MSELoss().type(dtype).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    p = get_params('net', net, net_input)  # network parameters to be optimized\n",
    "    optimizer = optim.Adam(p, lr=lr)\n",
    "\n",
    "    # Optimize\n",
    "\n",
    "    loss_history = []\n",
    "    psnr_history = []\n",
    "    ssim_history = []\n",
    "    variance_history = []\n",
    "    x_axis = []\n",
    "    earlystop = EarlyStop(size=buffer_size,patience=patience)\n",
    "    def closure(iterator):\n",
    "        #DIP\n",
    "        net_input_perturbed = net_input + zeros_like(net_input).normal_(std=reg_noise_std)\n",
    "        r_img_torch = net(net_input_perturbed)\n",
    "        total_loss = criterion(r_img_torch, img_noisy_torch)\n",
    "        total_loss.backward()\n",
    "        loss_history.append(total_loss.item())\n",
    "        if iterator % show_every == 0:\n",
    "            # evaluate recovered image (PSNR, SSIM)\n",
    "            r_img_np = torch_to_np(r_img_torch)\n",
    "            psnr = skimage.metrics.peak_signal_noise_ratio(img_np, r_img_np)\n",
    "            temp_img_np = np.transpose(img_np,(1,2,0))\n",
    "            temp_r_img_np = np.transpose(r_img_np,(1,2,0))\n",
    "            data_range = temp_img_np.max() - temp_img_np.min()\n",
    "            if n_channels == 1:\n",
    "                multichannel = False\n",
    "            else:\n",
    "                multichannel = True\n",
    "            ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=multichannel, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "            psnr_history.append(psnr)\n",
    "            ssim_history.append(ssim)\n",
    "            \n",
    "            #variance hisotry\n",
    "            r_img_np = r_img_np.reshape(-1)\n",
    "            earlystop.update_img_collection(r_img_np)\n",
    "            img_collection = earlystop.get_img_collection()\n",
    "            if iterator % (show_every*10) == 0:\n",
    "                print(f'Iteration %05d    Loss %.4f' % (iterator, total_loss.item()) + '    PSNR %.4f' % (psnr) + '    SSIM %.4f' % (ssim))\n",
    "                nni.report_intermediate_result(psnr)\n",
    "            if len(img_collection) == buffer_size:\n",
    "                ave_img = np.mean(img_collection,axis = 0)\n",
    "                variance = []\n",
    "                for tmp in img_collection:\n",
    "                    variance.append(MSE(ave_img, tmp))\n",
    "                cur_var = np.mean(variance)\n",
    "                cur_epoch = iterator\n",
    "                variance_history.append(cur_var)\n",
    "                x_axis.append(cur_epoch)\n",
    "                if earlystop.stop == False:\n",
    "                    earlystop.stop = earlystop.check_stop(cur_var, cur_epoch)\n",
    "        if earlystop.stop:\n",
    "            # Report final PSNR to NNI\n",
    "            nni.report_final_result(psnr)\n",
    "            return \"STOP\"\n",
    "        return total_loss, psnr\n",
    "        \n",
    "    for iterator in range(num_iter):\n",
    "        optimizer.zero_grad()\n",
    "        early_stop, psnr = closure(iterator)\n",
    "        optimizer.step()\n",
    "\n",
    "        if early_stop == \"STOP\":\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "    \n",
    "    if earlystop.stop != \"STOP\":\n",
    "        nni.report_final_result(psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import numpy as np\n",
    "import skimage\n",
    "import torch\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import LightningModule, Trainer   \n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT # change to lightning.pytorch.utilities.types\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as skimage_psnr\n",
    "\n",
    "from torch import optim, tensor, zeros_like\n",
    "from typing import Any, Optional\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.early_stop import EarlyStop, MSE, MAE\n",
    "from darts.noises import add_selected_noise\n",
    "from darts.phantom import generate_phantom\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "class SingleImageDataset(Dataset):\n",
    "    def __init__(self, image, num_iter):\n",
    "        self.image = image\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iter\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Always return the same image (and maybe a noise tensor or other information if necessary)\n",
    "        return self.image\n",
    "\n",
    "class LightningEval(LightningModule):\n",
    "    def __init__(self, model_cls, phantom=None, buffer_size=100, patience=600, num_iter=1200, show_every=1, \n",
    "                lr=0.00005, noise_type='gaussian', noise_factor=0.1, resolution=6, \n",
    "                n_channels=1, reg_noise_std_val=1./30.):\n",
    "        super(LightningEval, self).__init__()\n",
    "\n",
    "        # input\n",
    "        self.phantom = phantom\n",
    "\n",
    "        # Model\n",
    "        self.net = model_cls.to(self.device)\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.MSELoss().to(self.device)\n",
    "        \n",
    "        # Hyperparameters / Inputs\n",
    "        self.buffer_size = buffer_size\n",
    "        self.patience = patience\n",
    "        self.num_iter = num_iter\n",
    "        self.show_every = show_every\n",
    "        self.lr = lr\n",
    "        self.noise_type = noise_type\n",
    "        self.noise_factor = noise_factor\n",
    "        self.resolution = resolution\n",
    "        self.n_channels = n_channels\n",
    "        self.reg_noise_std = tensor(reg_noise_std_val)\n",
    "\n",
    "        # adjusting input\n",
    "        if self.phantom is None:\n",
    "            self.img_np, _, _, self.img_noisy_torch = self.preprocess_image(self.resolution, self.noise_type, self.noise_factor)\n",
    "        else:\n",
    "            self.img_np, _, _, self.img_noisy_torch = self.preprocess_image(self.resolution, self.noise_type, self.noise_factor, input_img_np=self.phantom)\n",
    "        self.net_input = get_noise(input_depth=1, spatial_size=self.img_np.shape[1], noise_type=self.noise_type)\n",
    "        \n",
    "        # History and early stopper\n",
    "        self.loss_history = []\n",
    "        self.psnr_history = []\n",
    "        self.ssim_history = []\n",
    "        self.variance_history = []\n",
    "        self.x_axis = []\n",
    "        self.earlystop = EarlyStop(size=self.buffer_size, patience=self.patience)\n",
    "        \n",
    "        \n",
    "    def forward(self, net_input):\n",
    "        net_input_perturbed = net_input + zeros_like(net_input).normal_(std=self.reg_noise_std)\n",
    "        return self.net(net_input_perturbed)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Deep Image Prior\n",
    "\n",
    "        training here follows closely from the following two repos: \n",
    "            - the deep image prior repo\n",
    "            - a DIP early stopping repo (Lighting has early stopping but it's not the same as the one used in the DIP repo)\n",
    "        \"\"\"        \n",
    "\n",
    "        r_img_torch = self.forward(self.net_input)\n",
    "        total_loss = self.criterion(r_img_torch, self.img_noisy_torch)\n",
    "\n",
    "        # Using global_step to count iterations\n",
    "        iterator = self.global_step\n",
    "\n",
    "        self.loss_history.append(total_loss.item())\n",
    "\n",
    "        if iterator % self.show_every == 0:\n",
    "            # evaluate recovered image (PSNR, SSIM)\n",
    "            r_img_np = torch_to_np(r_img_torch)\n",
    "            psnr = skimage_psnr(self.img_np, r_img_np)\n",
    "            temp_img_np = np.transpose(self.img_np, (1, 2, 0))\n",
    "            temp_r_img_np = np.transpose(r_img_np, (1, 2, 0))\n",
    "            data_range = temp_img_np.max() - temp_img_np.min()\n",
    "            if self.n_channels == 1:\n",
    "                multichannel = False\n",
    "            else:\n",
    "                multichannel = True\n",
    "            ssim = skimage.metrics.structural_similarity(temp_img_np, temp_r_img_np, multichannel=multichannel, win_size=7, channel_axis=-1, data_range=data_range)\n",
    "            self.psnr_history.append(psnr)\n",
    "            self.ssim_history.append(ssim)\n",
    "            \n",
    "            # variance history\n",
    "            r_img_np = r_img_np.reshape(-1)\n",
    "            self.earlystop.update_img_collection(r_img_np)\n",
    "            img_collection = self.earlystop.get_img_collection()\n",
    "            if iterator % (self.show_every * 10) == 0:\n",
    "                self.logger.log_metrics({'loss': total_loss.item(), 'psnr': psnr, 'ssim': ssim})\n",
    "                nni.report_intermediate_result(psnr)\n",
    "            if len(img_collection) == self.buffer_size:\n",
    "                ave_img = np.mean(img_collection, axis=0)\n",
    "                variance = [MSE(ave_img, tmp) for tmp in img_collection]\n",
    "                cur_var = np.mean(variance)\n",
    "                cur_epoch = iterator\n",
    "                self.variance_history.append(cur_var)\n",
    "                self.x_axis.append(cur_epoch)\n",
    "                if not self.earlystop.stop:\n",
    "                    self.earlystop.stop = self.earlystop.check_stop(cur_var, cur_epoch)\n",
    "        if self.earlystop.stop:\n",
    "            nni.report_final_result(psnr)\n",
    "            return {\"loss\": total_loss}\n",
    "        return {\"loss\": total_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Basic Adam Optimizer\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Dummy DataLoader that returns nothing but makes PyTorch Lightning's training loop work\n",
    "        \"\"\"\n",
    "        dataset = SingleImageDataset(self.phantom, self.num_iter)\n",
    "        return DataLoader(dataset, batch_size=1)\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"\n",
    "        Move all tensors to the GPU to begin training\n",
    "        \"\"\"\n",
    "        self.net.to(self.device)\n",
    "        self.net_input = self.net_input.to(self.device)\n",
    "        self.img_noisy_torch = self.img_noisy_torch.to(self.device)\n",
    "        self.reg_noise_std = self.reg_noise_std.to(self.device)\n",
    "\n",
    "    def on_train_end(self, **kwargs: Any):\n",
    "        \"\"\"\n",
    "        Report final PSNR to NNI and display the results\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.log_metrics({'loss': self.latest_loss, 'psnr': self.latest_psnr})\n",
    "        nni.report_final_result(self.latest_psnr)\n",
    "\n",
    "        denoised_img = self.forward(self.net_input).detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "        ax[0].imshow(self.img_np.squeeze(), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(denoised_img, cmap='gray')\n",
    "        ax[1].set_title(\"Denoised Image\")\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(self.img_noisy_torch.detach().cpu().squeeze().numpy(), cmap='gray')\n",
    "        ax[2].set_title(\"Noisy Image\")\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def preprocess_image(self, resolution, noise_type, noise_factor, input_img_np=None):\n",
    "        \"\"\"\n",
    "        Generates an image (or takes an input phantom), adds noise, and converts it to both numpy and torch tensors.\n",
    "\n",
    "        Args:\n",
    "        - resolution (int): Resolution for the phantom image.\n",
    "        - noise_type (str): Type of noise to add.\n",
    "        - noise_factor (float): Noise factor.\n",
    "        - input_img_np (numpy.ndarray, optional): Input raw image in numpy format. If not provided, a new image will be generated.\n",
    "\n",
    "        Returns:\n",
    "        - img_np (numpy.ndarray): Original image in numpy format.\n",
    "        - img_noisy_np (numpy.ndarray): Noisy image in numpy format.\n",
    "        - img_torch (torch.Tensor): Original image in torch tensor format.\n",
    "        - img_noisy_torch (torch.Tensor): Noisy image in torch tensor format.\n",
    "        \"\"\"\n",
    "        if input_img_np is None:\n",
    "            raw_img_np = generate_phantom(resolution=resolution) # 1x64x64 np array\n",
    "        else:\n",
    "            raw_img_np = input_img_np.copy() # 1x64x64 np array\n",
    "            \n",
    "        img_np = raw_img_np.copy() # 1x64x64 np array\n",
    "        img_torch = torch.tensor(raw_img_np, dtype=torch.float32).unsqueeze(0) # 1x1x64x64 torch tensor\n",
    "        img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type, noise_factor=noise_factor) # 1x1x64x64 torch tensor\n",
    "        img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 1x64x64 np array\n",
    "        \n",
    "        return img_np, img_noisy_np, img_torch, img_noisy_torch\n",
    "    \n",
    "    def validation_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT | None:\n",
    "        pass\n",
    "\n",
    "    def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT | None:\n",
    "        pass\n",
    "    \n",
    "class MyEarlyStopping(EarlyStopping):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # override this to disable early stopping at the end of val loop\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        # instead, do it at the end of training loop\n",
    "        self._run_early_stopping_check(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = generate_phantom(resolution=6)\n",
    "# model = SimpleAutoencoder()\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEval(model, phantom=phantom)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(max_epochs=5)\n",
    "\n",
    "# # Train the model\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = generate_phantom(resolution=6)\n",
    "\n",
    "model = SimpleAutoencoder()\n",
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEval(model, phantom=phantom)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(max_epochs=5)\n",
    "\n",
    "# # Train the model\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from nni import trace\n",
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "from darts.eval import main_evaluation\n",
    "\n",
    "from collections import OrderedDict\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "@trace\n",
    "@model_wrapper\n",
    "class SimpleAutoencoderSpace(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        out_layers = OrderedDict(\n",
    "            [\n",
    "            (\"RelU\", nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.ReLU())),\n",
    "            \n",
    "            (\"Sigmoid\", nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.Sigmoid())),\n",
    "            (\"SiLU\",  nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.SiLU())),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.out = nn.LayerChoice(out_layers,label='out')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phantom = generate_phantom(resolution=6)\n",
    "\n",
    "model = SimpleAutoencoder()\n",
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEval(model, phantom=phantom)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SimpleAutoencoderSpace()\n",
    "module = LightningEval(model_space, phantom=phantom)\n",
    "evaluator = FunctionalEvaluator(module)\n",
    "\n",
    "# search strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "search_strategy = strategy.DARTS()\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, None, search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "# exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch import LightningModule, Trainer   \n",
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as skimage_psnr\n",
    "\n",
    "from torch import optim, tensor, zeros_like\n",
    "\n",
    "from darts.common_utils import *\n",
    "from darts.noises import add_selected_noise\n",
    "from darts.phantom import generate_phantom\n",
    "\n",
    "from torch.utils.data import Dataset #, DataLoader\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "class SingleImageDataset(Dataset):\n",
    "    def __init__(self, image, num_iter):\n",
    "        self.image = image\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iter\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Always return the same image (and maybe a noise tensor or other information if necessary)\n",
    "        return self.image\n",
    "\n",
    "class SimpleLightningEval(LightningModule):\n",
    "    def __init__(self, model_cls, phantom=None, num_iter=1000, show_every=1, \n",
    "                lr=0.00005, noise_type='gaussian', noise_factor=0.1, resolution=6, \n",
    "                n_channels=1, reg_noise_std_val=1./30.):\n",
    "        super(SimpleLightningEval, self).__init__()\n",
    "\n",
    "        # input\n",
    "        self.phantom = phantom\n",
    "\n",
    "        # Model\n",
    "        self.net = model_cls.to(self.device)\n",
    "\n",
    "        # Loss\n",
    "        self.criterion = nn.MSELoss().to(self.device)\n",
    "        \n",
    "        # Hyperparameters / Inputs\n",
    "        self.num_iter = num_iter\n",
    "        self.show_every = show_every\n",
    "        self.lr = lr\n",
    "        self.noise_type = noise_type\n",
    "        self.noise_factor = noise_factor\n",
    "        self.resolution = resolution\n",
    "        self.n_channels = n_channels\n",
    "        self.reg_noise_std = tensor(reg_noise_std_val)\n",
    "\n",
    "        # adjusting input\n",
    "        if self.phantom is None:\n",
    "            self.img_np, _, _, self.img_noisy_torch = self.preprocess_image(self.resolution, self.noise_type, self.noise_factor)\n",
    "        else:\n",
    "            self.img_np, _, _, self.img_noisy_torch = self.preprocess_image(self.resolution, self.noise_type, self.noise_factor, input_img_np=self.phantom)\n",
    "        self.net_input = get_noise(input_depth=1, spatial_size=self.img_np.shape[1], noise_type=self.noise_type)\n",
    "        \n",
    "        \n",
    "    def forward(self, net_input):\n",
    "        net_input_perturbed = net_input + zeros_like(net_input).normal_(std=self.reg_noise_std)\n",
    "        return self.net(net_input_perturbed)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Deep Image Prior\n",
    "\n",
    "        training here follows closely from the following two repos: \n",
    "            - the deep image prior repo\n",
    "            - a DIP early stopping repo (Lighting has early stopping but it's not the same as the one used in the DIP repo)\n",
    "        \"\"\"        \n",
    "\n",
    "        r_img_torch = self.forward(self.net_input)\n",
    "        total_loss = self.criterion(r_img_torch, self.img_noisy_torch)\n",
    "\n",
    "        # Using global_step to count iterations\n",
    "        iterator = self.global_step\n",
    "\n",
    "        # evaluate recovered image (PSNR)\n",
    "        r_img_np = torch_to_np(r_img_torch)\n",
    "        psnr = skimage_psnr(self.img_np, r_img_np)\n",
    "        self.latest_psnr = psnr\n",
    "        self.latest_loss = total_loss.item()\n",
    "\n",
    "        if iterator % (self.show_every * 10) == 0:\n",
    "            self.logger.log_metrics({'loss': total_loss.item(), 'psnr': psnr})\n",
    "            self.log('psnr', psnr)\n",
    "            self.log('loss',total_loss.item())\n",
    "            nni.report_intermediate_result(psnr)\n",
    "\n",
    "        return {\"loss\": total_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Basic Adam Optimizer\n",
    "        \"\"\"\n",
    "        optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Dummy DataLoader that returns nothing but makes PyTorch Lightning's training loop work\n",
    "        \"\"\"\n",
    "        dataset = SingleImageDataset(self.phantom, self.num_iter)\n",
    "        return DataLoader(dataset, batch_size=1)\n",
    "    \n",
    "    def on_train_start(self):\n",
    "        \"\"\"\n",
    "        Move all tensors to the GPU to begin training\n",
    "        \"\"\"\n",
    "        self.net.to(self.device)\n",
    "        self.net_input = self.net_input.to(self.device)\n",
    "        self.img_noisy_torch = self.img_noisy_torch.to(self.device)\n",
    "        self.reg_noise_std = self.reg_noise_std.to(self.device)\n",
    "\n",
    "    def on_train_end(self, **kwargs: Any):\n",
    "        \"\"\"\n",
    "        Report final PSNR to NNI and display the results\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.log_metrics({'loss': self.latest_loss, 'psnr': self.latest_psnr})\n",
    "        nni.report_final_result(self.latest_psnr)\n",
    "\n",
    "        denoised_img = self.forward(self.net_input).detach().cpu().squeeze().numpy()\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "        ax[0].imshow(self.img_np.squeeze(), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].imshow(denoised_img, cmap='gray')\n",
    "        ax[1].set_title(\"Denoised Image\")\n",
    "        ax[1].axis('off')\n",
    "\n",
    "        ax[2].imshow(self.img_noisy_torch.detach().cpu().squeeze().numpy(), cmap='gray')\n",
    "        ax[2].set_title(\"Noisy Image\")\n",
    "        ax[2].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def preprocess_image(self, resolution, noise_type, noise_factor, input_img_np=None):\n",
    "        \"\"\"\n",
    "        Generates an image (or takes an input phantom), adds noise, and converts it to both numpy and torch tensors.\n",
    "\n",
    "        Args:\n",
    "        - resolution (int): Resolution for the phantom image.\n",
    "        - noise_type (str): Type of noise to add.\n",
    "        - noise_factor (float): Noise factor.\n",
    "        - input_img_np (numpy.ndarray, optional): Input raw image in numpy format. If not provided, a new image will be generated.\n",
    "\n",
    "        Returns:\n",
    "        - img_np (numpy.ndarray): Original image in numpy format.\n",
    "        - img_noisy_np (numpy.ndarray): Noisy image in numpy format.\n",
    "        - img_torch (torch.Tensor): Original image in torch tensor format.\n",
    "        - img_noisy_torch (torch.Tensor): Noisy image in torch tensor format.\n",
    "        \"\"\"\n",
    "        if input_img_np is None:\n",
    "            raw_img_np = generate_phantom(resolution=resolution) # 1x64x64 np array\n",
    "        else:\n",
    "            raw_img_np = input_img_np.copy() # 1x64x64 np array\n",
    "            \n",
    "        img_np = raw_img_np.copy() # 1x64x64 np array\n",
    "        img_torch = torch.tensor(raw_img_np, dtype=torch.float32).unsqueeze(0) # 1x1x64x64 torch tensor\n",
    "        img_noisy_torch = add_selected_noise(img_torch, noise_type=noise_type, noise_factor=noise_factor) # 1x1x64x64 torch tensor\n",
    "        img_noisy_np = img_noisy_torch.squeeze(0).numpy() # 1x64x64 np array\n",
    "        \n",
    "        return img_np, img_noisy_np, img_torch, img_noisy_torch\n",
    "    \n",
    "    def validation_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT | None:\n",
    "        pass\n",
    "\n",
    "    def test_step(self, *args: Any, **kwargs: Any) -> STEP_OUTPUT | None:\n",
    "        pass\n",
    "    \n",
    "class MyEarlyStopping(EarlyStopping):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # override this to disable early stopping at the end of val loop\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        # instead, do it at the end of training loop\n",
    "        self._run_early_stopping_check(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic_early_stopping = EarlyStopping(\n",
    "    monitor=\"loss\", \n",
    "    mode=\"min\", \n",
    "    patience=10, \n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "custom_early_stopping = MyEarlyStopping(\n",
    "    monitor=\"psnr\", \n",
    "    mode=\"max\", \n",
    "    patience=25, \n",
    "    verbose=True,\n",
    "    min_delta=0.1\n",
    "    )\n",
    "\n",
    "phantom = generate_phantom(resolution=6)\n",
    "\n",
    "# model = SimpleAutoencoder()\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "# Create the lightning module\n",
    "module = SimpleLightningEval(model, phantom=phantom)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "# trainer = Trainer(max_epochs=3)\n",
    "trainer = Trainer(callbacks=[custom_early_stopping], max_epochs=25)\n",
    "\n",
    "# # Train the model\n",
    "torch.set_float32_matmul_precision('medium')  # 'medium' precesion implies high speed; 'high' precision implies high accuracy (but lower speed)\n",
    "trainer.fit(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ms search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.strategy as strategy\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "\n",
    "from nni.retiarii import model_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model_wrapper\n",
    "class SimpleAutoencoderSpace(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        out_layers = OrderedDict(\n",
    "            [\n",
    "            (\"RelU\", nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.ReLU())),\n",
    "            \n",
    "            (\"Sigmoid\", nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.Sigmoid())),\n",
    "            (\"SiLU\",  nn.Sequential(\n",
    "                nn.ConvTranspose2d(1, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.SiLU())),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.out = nn.LayerChoice(out_layers,label='out')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the phantom\n",
    "phantom = generate_phantom(resolution=6)\n",
    "\n",
    "# Create a search space\n",
    "model_space = SimpleAutoencoderSpace()\n",
    "\n",
    "# Create a search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# Create a search algorithm\n",
    "module = SimpleLightningEval(model_space, phantom=phantom)\n",
    "\n",
    "# Create an Evaluator\n",
    "evaluator = FunctionalEvaluator(module)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "# trainer = Trainer(max_epochs=3)\n",
    "# # trainer = Trainer(callbacks=[early_stopping], max_epochs=25)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 250   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
