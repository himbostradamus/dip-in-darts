{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('MaxPool2d', MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))])\n",
      "[2023-09-02 16:27:20] \u001b[33mWARNING: No context found when `add_mutable()`. You are probably adding a MutableModule outside the `__init__` of a ModelSpace. This can possibly make the MutableModule untrackable and inconsistent: pool_1/input_1_0\u001b[0m\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No frozen context is found for CategoricalMultiple([0], n_chosen=1, label='pool_1/input_1_0'). Assuming no context. If you are using NAS, you are probably using `ensure_frozen` in forward, or outside the init of ModelSpace. Please avoid doing this as they will lead to erroneous results.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 174\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39moutput shape: \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    172\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest passed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 174\u001b[0m d \u001b[39m=\u001b[39m DARTS_UNet(depth\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m    175\u001b[0m d\u001b[39m.\u001b[39mtest()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/common/serializer.py:541\u001b[0m, in \u001b[0;36m_trace_cls.<locals>.wrapper.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m args, kwargs \u001b[39m=\u001b[39m _formulate_arguments(base\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m, args, kwargs, kw_only, is_class_init\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    539\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# calling serializable object init to initialize the full object\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(symbol\u001b[39m=\u001b[39;49mbase, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, call_super\u001b[39m=\u001b[39;49mcall_super)\n\u001b[1;32m    542\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRecursionError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    543\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    544\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mRecursion error detected in initialization of wrapped object. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mDid you use `super(MyClass, self).__init__()` rather than `super().__init__()`? \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[39mRuntimeWarning\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/common/serializer.py:144\u001b[0m, in \u001b[0;36mSerializableObject.__init__\u001b[0;34m(self, symbol, args, kwargs, call_super)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_nni_call_super\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m call_super\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m call_super:\n\u001b[1;32m    143\u001b[0m     \u001b[39m# call super means that the serializable object is by itself an object of the target class\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    145\u001b[0m         \u001b[39m*\u001b[39;49m[_argument_processor(arg) \u001b[39mfor\u001b[39;49;00m arg \u001b[39min\u001b[39;49;00m args],\n\u001b[1;32m    146\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{kw: _argument_processor(arg) \u001b[39mfor\u001b[39;49;00m kw, arg \u001b[39min\u001b[39;49;00m kwargs\u001b[39m.\u001b[39;49mitems()}\n\u001b[1;32m    147\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[13], line 118\u001b[0m, in \u001b[0;36mDARTS_UNet.__init__\u001b[0;34m(self, C_in, C_out, depth)\u001b[0m\n\u001b[1;32m    116\u001b[0m my_pools \u001b[39m=\u001b[39m pools()\n\u001b[1;32m    117\u001b[0m \u001b[39mprint\u001b[39m(my_pools)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoders\u001b[39m.\u001b[39mappend(Cell(my_pools, num_nodes\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, num_ops_per_node\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, num_predecessors\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpool_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoders\u001b[39m.\u001b[39mappend(Cell(convs(filters, filters\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m), num_nodes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, num_ops_per_node\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, num_predecessors\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconv_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m))\n\u001b[1;32m    120\u001b[0m filters \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/nn/pytorch/cell.py:295\u001b[0m, in \u001b[0;36mCell.__init__\u001b[0;34m(self, op_candidates, num_nodes, num_ops_per_node, num_predecessors, merge_op, preprocessor, postprocessor, concat_dim, label)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39m# fill-in the missing modules\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel_scope:\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_modules(op_candidates)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/nn/pytorch/cell.py:302\u001b[0m, in \u001b[0;36mCell._create_modules\u001b[0;34m(self, op_candidates)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mappend(nn\u001b[39m.\u001b[39mModuleList())\n\u001b[1;32m    301\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_ops_per_node):\n\u001b[0;32m--> 302\u001b[0m     inp \u001b[39m=\u001b[39m InputChoice(i, \u001b[39m1\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minput_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mk\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    303\u001b[0m     chosen \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inp, ChosenInputs):\n\u001b[1;32m    306\u001b[0m         \u001b[39m# now we are in the fixed mode\u001b[39;00m\n\u001b[1;32m    307\u001b[0m         \u001b[39m# the length of chosen should be 1\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/nn/pytorch/choice.py:301\u001b[0m, in \u001b[0;36mInputChoice.__init__\u001b[0;34m(self, n_candidates, n_chosen, reduction, weights, label)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_choice(n_candidates, n_chosen, weights, label)\n\u001b[1;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_mutable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchoice)\n\u001b[0;32m--> 301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dry_run_choice: Union[\u001b[39mint\u001b[39m, List[\u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m ensure_frozen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchoice)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/mutable/frozen.py:82\u001b[0m, in \u001b[0;36mensure_frozen\u001b[0;34m(mutable, strict, sample, retries)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[39mif\u001b[39;00m retries \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m (_ENSURE_FROZEN_STRICT \u001b[39mand\u001b[39;00m strict):\n\u001b[0;32m---> 82\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m     83\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNo frozen context is found for \u001b[39m\u001b[39m{\u001b[39;00mmutable\u001b[39m!r}\u001b[39;00m\u001b[39m. Assuming no context. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     84\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mIf you are using NAS, you are probably using `ensure_frozen` in forward, or outside the init of ModelSpace. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     85\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mPlease avoid doing this as they will lead to erroneous results.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     88\u001b[0m     \u001b[39m# TODO: Currently only mutable parameters in NAS evaluator end up here.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     \u001b[39m# It might cause consistency issues between multiple parameters without context.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[39m# I don't want to throw a warning here, but there should be a smarter way to do this.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39mreturn\u001b[39;00m mutable\u001b[39m.\u001b[39mrobust_default(retries\u001b[39m=\u001b[39mretries)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No frozen context is found for CategoricalMultiple([0], n_chosen=1, label='pool_1/input_1_0'). Assuming no context. If you are using NAS, you are probably using `ensure_frozen` in forward, or outside the init of ModelSpace. Please avoid doing this as they will lead to erroneous results."
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "from nni import trace\n",
    "import torch.nn as nn\n",
    "from nni.nas.nn.pytorch import Cell\n",
    "# import nni.retiarii.nn.pytorch as nn\n",
    "# from utils.common_utils import *\n",
    "\n",
    "@trace\n",
    "def conv_2d(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "        nn.Conv2d(C_out, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation\n",
    "    )\n",
    "\n",
    "@trace\n",
    "def depthwise_separable_conv(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_in, kernel_size=kernel_size, dilation=dilation, padding=padding, groups=C_in, bias=False),\n",
    "        nn.Conv2d(C_in, C_out, 1, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "        nn.Conv2d(C_out, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, groups=C_out, bias=False),\n",
    "        nn.Conv2d(C_out, C_out, 1, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation\n",
    "    )\n",
    "\n",
    "def pools():\n",
    "    pool_dict = OrderedDict([\n",
    "        (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2, padding=0)),\n",
    "        # (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2, padding=0)),\n",
    "        # (\"AdaMaxPool2d\", nn.AdaptiveMaxPool2d(1)),\n",
    "        # (\"AdaAvgPool2d\", nn.AdaptiveAvgPool2d(1)),\n",
    "        # (\"DepthToSpace\", nn.PixelShuffle(2)),\n",
    "    ])\n",
    "    return pool_dict\n",
    "\n",
    "def upsamples():\n",
    "    upsample_dict = OrderedDict([\n",
    "        (\"Upsample_nearest\", nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "        # (\"Upsample_bilinear\", nn.Upsample(scale_factor=2, mode='bilinear')),\n",
    "\n",
    "    ])\n",
    "    return upsample_dict\n",
    "\n",
    "def convs(C_in, C_out):\n",
    "    # all padding should follow this formula:\n",
    "    # pd = (ks - 1) * dl // 2\n",
    "    conv_dict = OrderedDict([\n",
    "        \n",
    "        # (\"conv2d_1x1_Relu\", conv_2d(C_in, C_out)),\n",
    "        # (\"conv2d_1x1_SiLU\", conv_2d(C_in, C_out, activation=nn.SiLU())),\n",
    "\n",
    "        (\"conv2d_3x3_Relu\", conv_2d(C_in, C_out, kernel_size=3, padding=1)),\n",
    "        (\"conv2d_3x3_SiLU\", conv_2d(C_in, C_out, kernel_size=3, padding=1, activation=nn.SiLU())),\n",
    "        (\"conv2d_3x3_Relu_1dil\", conv_2d(C_in, C_out, kernel_size=3, padding=2, dilation=2)),\n",
    "\n",
    "        # (\"conv2d_5x5_Relu\", conv_2d(C_in, C_out, kernel_size=5, padding=2)),\n",
    "        # (\"conv2d_5x5_Relu_1dil\", conv_2d(C_in, C_out, kernel_size=5, padding=4, dilation=2, activation=nn.SiLU())),\n",
    "        (\"conv2d_5x5_SiLU\", conv_2d(C_in, C_out, kernel_size=5, padding=2, activation=nn.SiLU())),\n",
    "\n",
    "\n",
    "        (\"convDS_1x1_Relu\", depthwise_separable_conv(C_in, C_out)),\n",
    "        # (\"convDS_1x1_SiLU\", depthwise_separable_conv(C_in, C_out, activation=nn.SiLU())),\n",
    "\n",
    "        (\"convDS_3x3_Relu\", depthwise_separable_conv(C_in, C_out, kernel_size=3, padding=1)),\n",
    "        # (\"convDS_3x3_SiLU\", depthwise_separable_conv(C_in, C_out, kernel_size=3, padding=1, activation=nn.SiLU())),\n",
    "\n",
    "        # (\"convDS_5x5_Relu\", depthwise_separable_conv(C_in, C_out, kernel_size=5, padding=2)),\n",
    "        # (\"convDS_5x5_SiLU\", depthwise_separable_conv(C_in, C_out, kernel_size=5, padding=2, activation=nn.SiLU())),\n",
    "    ])\n",
    "    return conv_dict\n",
    "\n",
    "# @trace\n",
    "# class Preprocessor(nn.Module):\n",
    "#     def __init__(self, C_in, C_out):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(C_in, C_out, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return [self.conv1(x[0])]\n",
    "\n",
    "# @trace\n",
    "# class Postprocessor(nn.Module):\n",
    "#     def __init__(self, C_in, C_out):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(C_in, C_out, kernel_size=3, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(C_in, C_out, kernel_size=3, padding=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return [self.conv1(x[0]), self.conv2(x[1])]\n",
    "\n",
    "@trace\n",
    "class DARTS_UNet(nn.Module):\n",
    "    def __init__(self, C_in=1, C_out=1, depth=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # all padding should follow this formula:\n",
    "        # pd = (ks - 1) * dl // 2\n",
    "        self.pr = False\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.in_layer = nn.Conv2d(C_in, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Encoders\n",
    "        filters = 64\n",
    "        self.encoders = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            my_pools = pools()\n",
    "            print(my_pools)\n",
    "            self.encoders.append(Cell(my_pools, num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'pool_{i+1}'))\n",
    "            self.encoders.append(Cell(convs(filters, filters*2), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'conv_{i+1}'))\n",
    "            filters *= 2\n",
    "\n",
    "        # Decoders\n",
    "        self.decoders = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            us = upsamples()\n",
    "            print(\"US\", us)\n",
    "            self.decoders.append(Cell(us, num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'upsample_{i+1}'))\n",
    "            filters //= 2\n",
    "            self.decoders.append(Cell(convs(filters*3, filters), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'conv_{i+1+depth}'))\n",
    "\n",
    "        self.out_layer = nn.Conv2d(64, C_out, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        if self.pr:\n",
    "            print(f'input shape: {x.shape}\\n')\n",
    "\n",
    "        x = self.in_layer(x)  # Apply the initial layer\n",
    "        skip_connections = [x]\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x = self.encoders[2*i]([x])\n",
    "            x = self.encoders[2*i+1]([x])\n",
    "            skip_connections.append(x)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            upsampled = self.decoders[2*i]([x])\n",
    "            cropped = self.crop_tensor(upsampled, skip_connections[-(i+2)])\n",
    "            x = torch.cat([cropped, upsampled], 1)\n",
    "            x = self.decoders[2*i+1]([x])\n",
    "\n",
    "        x = self.out_layer(x)  # Apply the final layer\n",
    "\n",
    "        return x\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        This will input a random tensor of 1x1x128x128 and test the forward pass.\n",
    "        \"\"\"\n",
    "        self.pr = True\n",
    "        x = torch.randn(1, 1, 128, 128)\n",
    "        y = self.forward(x)\n",
    "        assert y.shape == (1, 1, 128, 128), \"Output shape should be (1, 1, 128, 128), got {}\".format(y.shape)\n",
    "        print(f'output shape: {y.shape}\\n')\n",
    "        print(\"Test passed.\\n\\n\")\n",
    "\n",
    "d = DARTS_UNet(depth=4)\n",
    "d.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
