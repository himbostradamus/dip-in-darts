{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class Convolutions(nn.Module):\n",
    "    def __init__(self, conv, layer_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.LayerChoice(conv, label=f'{layer_name} - Step 2: Convolutions, Batchnorm and Activation')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, activation):\n",
    "        layers = [\n",
    "            (\"Conv2d\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            ),\n",
    "            (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl, groups=out_channels),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                activation\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        return OrderedDict(layers)\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, downsamples, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = downsamples\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv_layer(x)\n",
    "        return x\n",
    "\n",
    "class DecoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, upsamples, layer_name):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.upsample = upsamples\n",
    "        self.conv_layer = Convolutions(self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl, activations), layer_name)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(BaseBlock):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        ks = 5\n",
    "        dl = 3\n",
    "        pd = (ks - 1) * dl // 2\n",
    "\n",
    "        activation = nn.SiLU(inplace=True)\n",
    "\n",
    "        self.downsamples = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.upsamples = nn.Upsample(scale_factor=2,mode='nearest')\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.mid_channels = 64\n",
    "        self.first = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.mid_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(self.mid_channels),\n",
    "                activation,\n",
    "                nn.Conv2d(self.mid_channels, self.mid_channels, kernel_size=ks, padding=pd, dilation=dl),\n",
    "                nn.BatchNorm2d(self.mid_channels),\n",
    "                activation\n",
    "                )\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(self.mid_channels, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.first(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni\n",
    "import torch\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from darts.eval import main_evaluation\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "search_strategy = strategy.DARTS()\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
