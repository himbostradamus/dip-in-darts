{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "from collections import OrderedDict\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new space test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # let's make the DARST search space:\n",
    "# it's comprised of the following:\n",
    "# Max pooling 3x3\n",
    "# Average pooling 3x3\n",
    "# Skip connect (Identity)\n",
    "# Separable convolution 3x3\n",
    "# Separable convolution 5x5\n",
    "# Dilated convolution 3x3\n",
    "# Dilated convolution 5x5\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "    def SeparableConv2d(self, in_channels, out_channels, kernel, activation):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=kernel, stride=1, padding=(kernel - 1) // 2, dilation=1, groups=in_channels),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1),            \n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            activation,\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel, stride=1, padding=(kernel - 1) // 2, dilation=1, groups=out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            activation\n",
    "            )\n",
    "\n",
    "    def DilatedConv2d(self, in_channels, out_channels, kernel, dilation, activation):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=1, padding=(kernel - 1) // 2, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            activation,\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel, stride=1, padding=(kernel - 1) // 2, dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            activation\n",
    "            )\n",
    "    \n",
    "    def get_blocks(self, in_channels, out_channels, activation):\n",
    "        blocks = OrderedDict([    \n",
    "            ('SeparableConv2d_3x3', self.SeparableConv2d(in_channels, out_channels, kernel=3, activation=activation)),\n",
    "            ('SeparableConv2d_5x5', self.SeparableConv2d(in_channels, out_channels, kernel=5, activation=activation)),\n",
    "            ('DilatedConv2d_3x3', self.DilatedConv2d(in_channels, out_channels, kernel=3, dilation=2, activation=activation)),\n",
    "            ('DilatedConv2d_5x5', self.DilatedConv2d(in_channels, out_channels, kernel=5, dilation=2, activation=activation)),\n",
    "        ])\n",
    "        return blocks\n",
    "    \n",
    "    def get_pools(self):\n",
    "        pools = OrderedDict([\n",
    "            ('MaxPool2d', nn.MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)),\n",
    "            ('AvgPool2d', nn.AvgPool2d(kernel_size=3, stride=1, padding=1))\n",
    "        ])\n",
    "        return pools\n",
    "    \n",
    "    def get_upsamples(self):\n",
    "        upsamples = OrderedDict([\n",
    "            (\"Nearest\", nn.Upsample(scale_factor=2,mode='nearest')),\n",
    "            (\"Bilinear\", nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True))\n",
    "        ])\n",
    "        return upsamples\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(Block):\n",
    "    def __init__(self, in_channels, out_channels, activation, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = nn.LayerChoice(self.get_pools(),label=f'{layer_name} - Step 1: Downsample')\n",
    "        self.conv = nn.LayerChoice(self.get_blocks(in_channels,out_channels,activation),label=f'{layer_name} - Step 2: Convolution')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.convconv_layer(x)\n",
    "        return x\n",
    "    \n",
    "class DecoderBlock(Block):\n",
    "    def __init__(self, in_channels, out_channels, activation, layer_name=\"Decoder []\"):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.upsample = nn.LayerChoice(self.get_upsamples(),label=f'{layer_name} - Step 1: Upsample')\n",
    "        self.conv = nn.LayerChoice(self.get_blocks(in_channels,out_channels,activation),label=f'{layer_name} - Step 2: Convolution')\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activations = OrderedDict([\n",
    "    (\"RelU\", nn.ReLU(inplace=True)),\n",
    "    (\"Sigmoid\", nn.Sigmoid()),\n",
    "    (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "])\n",
    "\n",
    "DecoderBlock(3,16,activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(Block):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        network_depth = nn.ValueChoice([1, 2, 3, 4], label=\"Network Depth\")\n",
    "        # maybe can use max of depth to create a better label down in the decoder_block = ... line below\n",
    "\n",
    "        activations = OrderedDict([\n",
    "            (\"RelU\", nn.ReLU(inplace=True)),\n",
    "            (\"Sigmoid\", nn.Sigmoid()),\n",
    "            (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "        ])\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.mid_channels = 64\n",
    "        self.conv = nn.LayerChoice(self.get_blocks(in_channels,out_channels,activations),label=f'{\"First Conv Layer\"} - Step 1: Convolution')\n",
    "\n",
    "\n",
    "        # For Encoders:\n",
    "        encoder_block = lambda index: EncoderBlock(64*(2**index), 64*(2**(index+1)), activations, f\"Encoder {index+1}\")\n",
    "        self.encoders = nn.Repeat(encoder_block, network_depth)\n",
    "\n",
    "        # For Decoders:\n",
    "        decoder_block = lambda index: DecoderBlock(64*(2**(index))*3, 64*(2**index), activations, f\"Decoder {index+1}\")\n",
    "        self.decoders = nn.Repeat(decoder_block, network_depth)\n",
    "        self.decoders = self.decoders[::-1]\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logger.info(\"Input: %s\", x.size())\n",
    "        \n",
    "        # Variables to store intermediate values\n",
    "        encoder_outputs = []\n",
    "\n",
    "        # Start with the first conv layer\n",
    "        x = self.first(x)\n",
    "        encoder_outputs.append(x)\n",
    "        logger.info(f\"Initial Conv Layer: %s\", x.size())\n",
    "\n",
    "        # Encoder pass\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            logger.info(f\"Encoder {i+1}: %s\", x.size())\n",
    "\n",
    "        # Decoder pass\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            x = decoder(x, encoder_outputs[-(i+2)])\n",
    "            logger.info(f\"Decoder {len(self.decoders) - i}: %s\", x.size())\n",
    "\n",
    "        x = self.out(x)\n",
    "        logger.info(\"Output: %s\", x.size())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from utils import main_evaluation\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from noises import *\n",
    "from utils import *\n",
    "from phantom import generate_phantom, phantom_to_torch\n",
    "\n",
    "\n",
    "def display_images(original, noisy):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Displaying the original image\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(TF.to_pil_image(original))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Displaying the noisy image\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(TF.to_pil_image(noisy))\n",
    "    plt.title(\"Noisy Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def test_noise_functions():\n",
    "    # Generate the phantom image and convert the numpy img to torch tensor\n",
    "    img_numpy = generate_phantom(resolution=6)\n",
    "    img = phantom_to_torch(img_numpy)\n",
    "    \n",
    "    for noise_name, noise_func in NOISE_FUNCTIONS.items():\n",
    "        noisy_img = add_selected_noise(img, noise_type=noise_name)\n",
    "        print(f\"Testing {noise_name} noise...\")\n",
    "        display_images(img, noisy_img)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_noise_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test old space with phantoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from darts.space import SearchSpace\n",
    "from darts.eval import main_evaluation\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 12   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
