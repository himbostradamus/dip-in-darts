{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_eval.eval_MultiTrial import Eval_MT\n",
    "from search_eval.optimizer.SingleImageDataset import SingleImageDataset\n",
    "from search_eval.utils.common_utils import *\n",
    "from search_space.search_space import DARTS_UNet\n",
    "\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "import nni.retiarii.serializer as serializer\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 1\n",
    "total_iterations = 1200\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{45}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{45}.npy')\n",
    "\n",
    "\n",
    "# Create the lightning module\n",
    "module = Eval_MT(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                num_iter=num_iter,\n",
    "                lr=0.01, \n",
    "                buffer_size=100,\n",
    "                patience=1000,\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            # callbacks=[early_stop_callback],\n",
    "            max_epochs=total_iterations/(2*num_iter),\n",
    "                # it's either in my code or the lighting but total iterations will end up being twice that of the input value to max_epochs\n",
    "                # that means that if you want 5000 iterations, you need to set max_epochs=2500\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = DARTS_UNet()\n",
    "\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}'\n",
    "\n",
    "exp_config.max_trial_number = 100   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8081)\n",
    "exported_arch = experiment.export_top_models()\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_arch = experiment.export_top_models()\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()\n",
    "\n",
    "# clear the cuda cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)\n",
    "\n",
    "resolution = 64\n",
    "\n",
    "for noise_level in ['0.05', '0.09', '0.15', '0.20']:\n",
    "    # may need to incorporate some logic to scale the number of iterations based on the noise level\n",
    "    total_iterations = 1200\n",
    "    for noise_type in ['gaussian', 'poisson']:\n",
    "        for img in range(0, 5):\n",
    "            phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img}.npy')\n",
    "            phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img}.npy')\n",
    "            # Create the lightning module\n",
    "            module = Eval_MT(\n",
    "                            phantom=phantom, \n",
    "                            phantom_noisy=phantom_noisy,\n",
    "                            lr=0.01, \n",
    "                            buffer_size=100,\n",
    "                            patience=1000,\n",
    "                            )\n",
    "\n",
    "            # Create a PyTorch Lightning trainer\n",
    "            trainer = Trainer(\n",
    "                        max_epochs=total_iterations,\n",
    "                        fast_dev_run=False,\n",
    "                        gpus=1,\n",
    "                        )\n",
    "\n",
    "            if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "                trainer.optimizer_frequencies = []\n",
    "\n",
    "            # Create the lighting object for evaluator\n",
    "            train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "            # Create a Search Space\n",
    "            model_space = DARTS_UNet()\n",
    "\n",
    "            # Configure and run the experiment for multi-strategy\n",
    "            experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "            exp_config = RetiariiExeConfig('local')\n",
    "            exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}'\n",
    "\n",
    "            exp_config.max_trial_number = 100   # spawn 4 trials at most\n",
    "            exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "            exp_config.trial_gpu_number = 1\n",
    "            exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "            experiment.run(exp_config, 8081)\n",
    "            exported_arch = experiment.export_top_models()\n",
    "            # write this out to a file\n",
    "            # include the image, hyperparameters, the architecture and the final loss\n",
    "            # this will be used to create a table of results\n",
    "            # also include the number of parameters\n",
    "\n",
    "            exported_arch\n",
    "\n",
    "            # stop the experiment\n",
    "            experiment.stop()\n",
    "\n",
    "            # clear the cuda cache\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
