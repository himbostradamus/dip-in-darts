{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_eval.eval_MultiTrial import Eval_MT\n",
    "from search_eval.optimizer.SingleImageDataset import SingleImageDataset\n",
    "from search_eval.utils.common_utils import *\n",
    "from search_space.search_space import DARTS_UNet\n",
    "\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "search_strategy = strategy.RegularizedEvolution(dedup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 700\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "phantom_num = 45\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{phantom_num}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{phantom_num}.npy')\n",
    "\n",
    "\n",
    "# Create the lightning module\n",
    "module = Eval_MT(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "\n",
    "                learning_rate=0.098, \n",
    "                buffer_size=700,\n",
    "                patience=150,\n",
    "                weight_decay=1.9e-7,\n",
    "                \n",
    "                report_every=10,\n",
    "                HPO=True\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = DARTS_UNet()\n",
    "\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}_p{phantom_num}_NT{noise_type}_NL{noise_level}'\n",
    "\n",
    "exp_config.max_trial_number = 250   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 3  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8889) # recommended in documentation was 8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_arch = experiment.export_top_models()\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()\n",
    "\n",
    "# clear the cuda cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)\n",
    "\n",
    "resolution = 64\n",
    "\n",
    "for noise_level in ['0.05', '0.09', '0.15', '0.20']:\n",
    "    # may need to incorporate some logic to scale the number of iterations based on the noise level\n",
    "    total_iterations = 1200\n",
    "    for noise_type in ['gaussian', 'poisson']:\n",
    "        for img in range(0, 5):\n",
    "            phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img}.npy')\n",
    "            phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img}.npy')\n",
    "            # Create the lightning module\n",
    "            module = Eval_MT(\n",
    "                            phantom=phantom, \n",
    "                            phantom_noisy=phantom_noisy,\n",
    "                            lr=0.01, \n",
    "                            buffer_size=100,\n",
    "                            patience=1000,\n",
    "                            )\n",
    "\n",
    "            # Create a PyTorch Lightning trainer\n",
    "            trainer = Trainer(\n",
    "                        max_epochs=total_iterations,\n",
    "                        fast_dev_run=False,\n",
    "                        gpus=1,\n",
    "                        )\n",
    "\n",
    "            if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "                trainer.optimizer_frequencies = []\n",
    "\n",
    "            # Create the lighting object for evaluator\n",
    "            train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "            # Create a Search Space\n",
    "            model_space = DARTS_UNet()\n",
    "\n",
    "            # Configure and run the experiment for multi-strategy\n",
    "            experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "            exp_config = RetiariiExeConfig('local')\n",
    "            exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}'\n",
    "\n",
    "            exp_config.max_trial_number = 100   # spawn 4 trials at most\n",
    "            exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "            exp_config.trial_gpu_number = 1\n",
    "            exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "            experiment.run(exp_config, 8081)\n",
    "            exported_arch = experiment.export_top_models()\n",
    "            # write this out to a file\n",
    "            # include the image, hyperparameters, the architecture and the final loss\n",
    "            # this will be used to create a table of results\n",
    "            # also include the number of parameters\n",
    "\n",
    "            exported_arch\n",
    "\n",
    "            # stop the experiment\n",
    "            experiment.stop()\n",
    "\n",
    "            # clear the cuda cache\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
