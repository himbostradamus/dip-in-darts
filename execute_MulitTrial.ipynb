{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "from search_eval.eval_MultiTrial import Eval_MT\n",
    "from search_eval.optimizer.SingleImageDataset import SingleImageDataset\n",
    "from search_eval.utils.common_utils import *\n",
    "from search_space.search_space import DARTS_UNet\n",
    "\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "import nni.retiarii.serializer as serializer\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-05 20:06:37] \u001b[32mCreating experiment, Experiment ID: \u001b[36mszkxmt6g\u001b[0m\n",
      "[2023-09-05 20:06:37] \u001b[32mStarting web server...\u001b[0m\n",
      "[2023-09-05 20:06:38] \u001b[32mSetting up...\u001b[0m\n",
      "[2023-09-05 20:06:39] \u001b[32mWeb portal URLs: \u001b[36mhttp://127.0.0.1:8889 http://10.128.0.3:8889\u001b[0m\n",
      "[2023-09-05 20:06:39] \u001b[32mDispatcher started\u001b[0m\n",
      "[2023-09-05 20:06:39] \u001b[32mStart strategy...\u001b[0m\n",
      "[2023-09-05 20:06:39] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "[2023-09-05 20:06:39] \u001b[32mRandom search running in fixed size mode. Dedup: on.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-05 20:07:41] \u001b[33mWARNING: KeyboardInterrupt detected\u001b[0m\n",
      "[2023-09-05 20:07:41] \u001b[32mStopping experiment, please wait...\u001b[0m\n",
      "[2023-09-05 20:07:41] \u001b[32mDispatcher exiting...\u001b[0m\n",
      "[2023-09-05 20:07:42] \u001b[32mDispatcher terminiated\u001b[0m\n",
      "[2023-09-05 20:07:42] \u001b[32mExperiment stopped\u001b[0m\n",
      "[2023-09-05 20:07:42] \u001b[32mSearch process is done, the experiment is still alive, `stop()` can terminate the experiment.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_iterations = 1200\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{45}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{45}.npy')\n",
    "\n",
    "\n",
    "# Create the lightning module\n",
    "module = Eval_MT(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "\n",
    "                learning_rate=0.01, \n",
    "                buffer_size=700,\n",
    "                patience=150,\n",
    "                weight_decay=2e-7,\n",
    "                \n",
    "                report_every=10\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = DARTS_UNet()\n",
    "\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}'\n",
    "\n",
    "exp_config.max_trial_number = 5   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8889) # recommended in documentation was 8081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_arch = experiment.export_top_models()\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-05 20:07:43] \u001b[32mStopping experiment, please wait...\u001b[0m\n",
      "[2023-09-05 20:07:43] \u001b[32mExperiment stopped\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "experiment.stop()\n",
    "\n",
    "# clear the cuda cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a Search Strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)\n",
    "\n",
    "resolution = 64\n",
    "\n",
    "for noise_level in ['0.05', '0.09', '0.15', '0.20']:\n",
    "    # may need to incorporate some logic to scale the number of iterations based on the noise level\n",
    "    total_iterations = 1200\n",
    "    for noise_type in ['gaussian', 'poisson']:\n",
    "        for img in range(0, 5):\n",
    "            phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img}.npy')\n",
    "            phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img}.npy')\n",
    "            # Create the lightning module\n",
    "            module = Eval_MT(\n",
    "                            phantom=phantom, \n",
    "                            phantom_noisy=phantom_noisy,\n",
    "                            lr=0.01, \n",
    "                            buffer_size=100,\n",
    "                            patience=1000,\n",
    "                            )\n",
    "\n",
    "            # Create a PyTorch Lightning trainer\n",
    "            trainer = Trainer(\n",
    "                        max_epochs=total_iterations,\n",
    "                        fast_dev_run=False,\n",
    "                        gpus=1,\n",
    "                        )\n",
    "\n",
    "            if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "                trainer.optimizer_frequencies = []\n",
    "\n",
    "            # Create the lighting object for evaluator\n",
    "            train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "            lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "            # Create a Search Space\n",
    "            model_space = DARTS_UNet()\n",
    "\n",
    "            # Configure and run the experiment for multi-strategy\n",
    "            experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "            exp_config = RetiariiExeConfig('local')\n",
    "            exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}'\n",
    "\n",
    "            exp_config.max_trial_number = 100   # spawn 4 trials at most\n",
    "            exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "            exp_config.trial_gpu_number = 1\n",
    "            exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "            experiment.run(exp_config, 8081)\n",
    "            exported_arch = experiment.export_top_models()\n",
    "            # write this out to a file\n",
    "            # include the image, hyperparameters, the architecture and the final loss\n",
    "            # this will be used to create a table of results\n",
    "            # also include the number of parameters\n",
    "\n",
    "            exported_arch\n",
    "\n",
    "            # stop the experiment\n",
    "            experiment.stop()\n",
    "\n",
    "            # clear the cuda cache\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
