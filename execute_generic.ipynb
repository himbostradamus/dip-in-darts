{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_eval.eval_generic import SGLDES\n",
    "from search_eval.optimizer.SingleImageDataset import SingleImageDataset\n",
    "from search_eval.utils.common_utils import *\n",
    "\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "import nni.retiarii.serializer as serializer\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration: \n",
    "\n",
    "### Search == One-Shot\n",
    "### SGLDES == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from search_space.unet.unetspaceOS import UNetSpace\n",
    "\n",
    "total_iterations = 650\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "img_id = np.random.randint(0, 50)\n",
    "\n",
    "\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img_id}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img_id}.npy')\n",
    "\n",
    "learning_rate = 0.095\n",
    "buffer_size = 100\n",
    "patience = 250\n",
    "weight_decay = 5e-7\n",
    "show_every = 200\n",
    "report_every = 25\n",
    "\n",
    "# Create the lightning module\n",
    "module = SGLDES(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                \n",
    "                learning_rate=learning_rate, # consider .01\n",
    "                buffer_size=buffer_size,\n",
    "                patience=patience,\n",
    "                weight_decay= weight_decay,\n",
    "\n",
    "                show_every=show_every,\n",
    "                report_every=report_every,\n",
    "                HPO=False,\n",
    "                NAS=True,\n",
    "                OneShot=True,\n",
    "                SGLD_regularize=False,\n",
    "                ES=True,\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom_noisy, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(phantom_noisy, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "\n",
    "# Select the Search Strategy\n",
    "# search_strategy = strategy.DARTS()\n",
    "# search_strategy = strategy.ENAS()\n",
    "search_strategy = strategy.GumbelDARTS()\n",
    "# search_strategy = strategy.RandomOneShot()\n",
    "\n",
    "\n",
    "# model_space = UNetSpace(\n",
    "#          C_in=1, \n",
    "#          C_out=1, \n",
    "#          depth=2, \n",
    "#          nodes_per_layer=1, # accept only 1 or 2,\n",
    "#          ops_per_node=4,\n",
    "#          use_attention=False,\n",
    "\n",
    "#         )\n",
    "\n",
    "model_space = UNetSpace(\n",
    "         C_in=1, \n",
    "         C_out=1, \n",
    "         depth=4, \n",
    "         nodes_per_layer=2, # accept only 1 or 2,\n",
    "         ops_per_node=4,\n",
    "         use_attention=True,\n",
    "\n",
    "        )\n",
    "# fast_dev_run=False\n",
    "\n",
    "config = RetiariiExeConfig(execution_engine='oneshot')\n",
    "experiment = RetiariiExperiment(model_space, evaluator=lightning, strategy=search_strategy)\n",
    "experiment.run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.export_top_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain top model\n",
    "from search_space.node_space import exportedModel\n",
    "from search_space.unet import exportedUNet\n",
    "from search_eval.eval_no_search_SGLD_ES import Eval_SGLD_ES\n",
    "\n",
    "# construct output and retrain\n",
    "exported_arch = experiment.export_top_models()[0]\n",
    "# extract value from key -- pool 0\n",
    "print(\"--------------------\")\n",
    "print(\"--------------------\")\n",
    "for i in range(depth):\n",
    "    print(f'pool {i+1}: ', exported_arch[f'pool {i}/op_1_0'])\n",
    "    print(f'encoder {i+1}: ', exported_arch[f'encoder {i}/op_1_0'])\n",
    "    print(\"--------------------\")\n",
    "for i in range(depth):\n",
    "    print(f'upsample {i+1}: ', exported_arch[f'upsample {i}/op_1_0'])\n",
    "    print(f'decoder {i+1}: ', exported_arch[f'decoder {i}/op_1_0'])\n",
    "    print(\"--------------------\")\n",
    "print(\"--------------------\\n\\n\\n\")\n",
    "\n",
    "model = exportedModel(1,1,depth,exported_arch)\n",
    "\n",
    "learning_rate = 0.01\n",
    "buffer_size = 100\n",
    "patience = 1500\n",
    "weight_decay = 5e-7\n",
    "show_every = 500\n",
    "report_every = 50\n",
    "\n",
    "print(f\"\\n\\n----------------------------------\")\n",
    "print(f'Experiment Configuration:')\n",
    "print(f'\\tTotal Iterations: {total_iterations}')\n",
    "\n",
    "print(f'\\tPatience: {patience}')\n",
    "print(f'\\tBuffer Size: {buffer_size}')\n",
    "print(f'\\tLearning Rate: {learning_rate}')\n",
    "print(f'\\tWeight Decay: {weight_decay}')\n",
    "\n",
    "print(f'\\tImage Resolution: {resolution}')\n",
    "print(f'\\tPlotting every {show_every} iterations')\n",
    "print(f\"----------------------------------\\n\\n\")\n",
    "\n",
    "# Create the lightning module\n",
    "module = Eval_SGLD_ES(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "\n",
    "                learning_rate=learning_rate, \n",
    "                buffer_size=buffer_size,\n",
    "                patience=patience,\n",
    "                weight_decay=weight_decay,\n",
    "                \n",
    "                report_every=report_every,\n",
    "                show_every=show_every,\n",
    "                model=model,\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop experiment and clear cache\n",
    "experiment.stop()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration: \n",
    "\n",
    "### Search == Multi-Trial\n",
    "### SGLDES == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_space.unet.unetspaceMT import UNetSpaceMT\n",
    "total_iterations = 800\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "\n",
    "img_id = 45 # np.random.randint(0, 50)\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img_id}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img_id}.npy')\n",
    "\n",
    "learning_rate = 0.1\n",
    "buffer_size = 100\n",
    "patience = 200\n",
    "weight_decay = 5e-8\n",
    "show_every = 200\n",
    "report_every = 25\n",
    "\n",
    "print(f\"\\n\\n----------------------------------\")\n",
    "print(f'Experiment Configuration:')\n",
    "print(f'\\tImage Config')\n",
    "print(f'\\t\\tImage ID: {img_id}')\n",
    "print(f'\\t\\tImage Resolution: {resolution}')\n",
    "print(f'\\t\\tNoise Type: {noise_type}')\n",
    "print(f'\\t\\tNoise Level: {noise_level}\\n')\n",
    "\n",
    "print(f'\\tTraining Config')\n",
    "print(f'\\t\\tTotal Iterations: {total_iterations}')\n",
    "print(f'\\t\\tBuffer Size: {buffer_size}')\n",
    "print(f'\\t\\tPatience: {patience}')\n",
    "print(f'\\t\\tLearning Rate: {learning_rate}')\n",
    "print(f'\\t\\tWeight Decay: {weight_decay}')\n",
    "print(f'\\t\\tPlotting every {show_every} iterations\\n')\n",
    "\n",
    "print(f\"----------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# Create the lightning module\n",
    "module = SGLDES(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                \n",
    "                learning_rate=learning_rate, # consider .01\n",
    "                buffer_size=buffer_size,\n",
    "                patience=patience,\n",
    "                weight_decay= weight_decay,\n",
    "\n",
    "                show_every=show_every,\n",
    "                report_every=report_every,\n",
    "                HPO=True,\n",
    "                NAS=True,\n",
    "                OneShot=False,\n",
    "                SGLD_regularize=True,\n",
    "                switch=None\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = trace(DataLoader)(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "\n",
    "# Create a Search Space\n",
    "model_space = UNetSpaceMT(depth=4, init_features=64)\n",
    "\n",
    "# Select a Search Strategy\n",
    "# search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "search_strategy = strategy.RegularizedEvolution(dedup=True)\n",
    "\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}_p{img_id}_NT{noise_type}_NL{noise_level}'\n",
    "\n",
    "exp_config.max_trial_number = 250   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 3  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8889) # recommended in documentation was 8081\n",
    "experiment = RetiariiExperiment(model_space, evaluator=lightning, strategy=search_strategy)\n",
    "experiment.run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration:\n",
    "\n",
    "### Search == None\n",
    "### SGLDES == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_space.unet.unet import UNet\n",
    "\n",
    "# INPUTS\n",
    "# Non HPO inputs\n",
    "total_iterations = 1000\n",
    "show_every = 100 #200\n",
    "report_every = 25 #25\n",
    "\n",
    "# HPO inputs\n",
    "#  note a smaller learning rate affecs the SGLD, so overfitting happens FASTER at LOWER learning rates (start with 0.01)\n",
    "learning_rate = .1 # 0.1089\n",
    "buffer_size = 100 # 500\n",
    "patience = 100\n",
    "weight_decay= 5e-8\n",
    "\n",
    "resolution = 64\n",
    "noise_level = 0.09\n",
    "noise_type = 'gaussian'\n",
    "img_id = np.random.randint(0, 50) # 45\n",
    "\n",
    "phantom = np.load(f'phantoms/ground_truth/{resolution}/{img_id}.npy')\n",
    "phantom_noisy= np.load(f'phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img_id}.npy')\n",
    "\n",
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "model = UNet(depth=4, init_features=64)\n",
    "\n",
    "\n",
    "print(f\"\\n\\n----------------------------------\")\n",
    "print(f'Experiment Configuration:')\n",
    "print(f'\\tImage Config')\n",
    "print(f'\\t\\tImage ID: {img_id}')\n",
    "print(f'\\t\\tImage Resolution: {resolution}')\n",
    "print(f'\\t\\tNoise Type: {noise_type}')\n",
    "print(f'\\t\\tNoise Level: {noise_level}\\n')\n",
    "\n",
    "print(f'\\tTraining Config:')\n",
    "print(f'\\t\\tTotal Iterations: {total_iterations}')\n",
    "print(f'\\t\\tBuffer Size: {buffer_size}')\n",
    "print(f'\\t\\tPatience: {patience}')\n",
    "print(f'\\t\\tLearning Rate: {learning_rate}')\n",
    "print(f'\\t\\tWeight Decay: {weight_decay}\\n')\n",
    "\n",
    "print(f'\\tLogging Config:')\n",
    "print(f'\\t\\tReport every: {report_every}')\n",
    "print(f'\\t\\tPlotting every {show_every} iterations\\n')\n",
    "print(f\"----------------------------------\\n\\n\")\n",
    "\n",
    "# Create the lightning module\n",
    "module = SGLDES(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                \n",
    "                learning_rate=learning_rate,\n",
    "                buffer_size=buffer_size,\n",
    "                patience=patience,\n",
    "                weight_decay= weight_decay,\n",
    "\n",
    "                show_every=show_every,\n",
    "                report_every=report_every,\n",
    "                HPO=False,\n",
    "                NAS=False,\n",
    "                OneShot=False,\n",
    "                SGLD_regularize=True,\n",
    "                switch=None\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the lightning module\n",
    "### this one works but we want to use the universal one if we can\n",
    "# module = Eval_SGLD_ES(\n",
    "#                 phantom=phantom, \n",
    "#                 phantom_noisy=phantom_noisy,\n",
    "\n",
    "#                 learning_rate=learning_rate, \n",
    "#                 buffer_size=buffer_size,\n",
    "#                 patience=patience,\n",
    "#                 weight_decay=weight_decay,\n",
    "                \n",
    "#                 report_every=report_every,\n",
    "#                 show_every=show_every,\n",
    "#                 model=model,\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration:\n",
    "\n",
    "### Search == None\n",
    "### SGLDES == False (SGLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_eval.utils.common_utils import *\n",
    "from search_eval.eval_SGLD import Eval_SGLD, SingleImageDataset\n",
    "\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "from search_space.unet.unet import UNet\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "# INPUTS\n",
    "total_iterations = 1400\n",
    "burnin_iter = 200\n",
    "show_every = 50\n",
    "lr = 0.1 #  note a smaller learning rate affecs the SGLD, so overfitting happens FASTER at LOWER learning rates (start with 0.01)\n",
    "\n",
    "model = UNet(in_channels=1, out_channels=1, init_features=64, depth=4)\n",
    "# model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "img_id = np.random.randint(0, 50)\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{img_id}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{img_id}.npy')\n",
    "\n",
    "print(f\"\\n\\n----------------------------------\")\n",
    "print(f'Experiment Configuration:')\n",
    "print(f'\\tImage Config')\n",
    "print(f'\\t\\tImage ID: {img_id}')\n",
    "print(f'\\t\\tImage Resolution: {resolution}')\n",
    "print(f'\\t\\tNoise Type: {noise_type}')\n",
    "print(f'\\t\\tNoise Level: {noise_level}\\n')\n",
    "\n",
    "print(f'\\tModel Config')\n",
    "print(f'\\t\\tModel: {model}\\n')\n",
    "\n",
    "print(f'\\tTraining Config')\n",
    "print(f'\\t\\tTotal Iterations: {total_iterations}')\n",
    "print(f'\\t\\tBurnin Iterations: {burnin_iter}')\n",
    "print(f'\\t\\tLearning Rate: {lr}')\n",
    "print(f'\\t\\tImage Resolution: {resolution}')\n",
    "print(f'\\t\\tPlotting every {show_every} iterations\\n')\n",
    "print(f\"----------------------------------\\n\\n\")\n",
    "# Create the lightning module\n",
    "module = Eval_SGLD(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                lr=lr, \n",
    "                burnin_iter=burnin_iter,\n",
    "                model=model, # model defaults to U-net \n",
    "                show_every=show_every\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=None)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
