{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from search_eval.eval_generic import SGLDES\n",
    "from search_eval.optimizer.SingleImageDataset import SingleImageDataset\n",
    "from search_eval.utils.common_utils import *\n",
    "# from search_space.search_space import SearchSpace\n",
    "from search_space.search_space_nodes import SearchSpace\n",
    "from search_space.node_space import NodeSpace\n",
    "from search_space.simple_space import SimpleSpace\n",
    "\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "import nni.retiarii.serializer as serializer\n",
    "\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_iterations = 35000\n",
    "\n",
    "resolution = 64\n",
    "noise_type = 'gaussian'\n",
    "noise_level = '0.09'\n",
    "phantom =       np.load(f'/home/joe/nas-for-dip/phantoms/ground_truth/{resolution}/{45}.npy')\n",
    "phantom_noisy = np.load(f'/home/joe/nas-for-dip/phantoms/{noise_type}/res_{resolution}/nl_{noise_level}/p_{45}.npy')\n",
    "\n",
    "# Create the lightning module\n",
    "module = SGLDES(\n",
    "                phantom=phantom, \n",
    "                phantom_noisy=phantom_noisy,\n",
    "                \n",
    "                learning_rate=0.001, # consider .01\n",
    "                buffer_size=2000,\n",
    "                patience=5000,\n",
    "                weight_decay= 5e-7,\n",
    "\n",
    "                show_every=500,\n",
    "                report_every=100,\n",
    "                HPO=False,\n",
    "                NAS=True,\n",
    "                OneShot=True,\n",
    "                SGLD_regularize=True,\n",
    "                switch=None\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=total_iterations,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "\n",
    "# Select the Search Strategy\n",
    "# search_strategy = strategy.DARTS()\n",
    "# search_strategy = strategy.DartsStrategy()\n",
    "# search_strategy = strategy.ENAS()\n",
    "search_strategy = strategy.GumbelDARTS()\n",
    "# search_strategy = strategy.RandomOneShot()\n",
    "\n",
    "# # Create a Search Space\n",
    "# model_space = SearchSpace(depth=4, enNodes=2)\n",
    "depth = 1\n",
    "nodes_per_layer = 1\n",
    "ops_per_node = 1\n",
    "poolOps_per_node = 1\n",
    "upsampleOps_per_node = 1\n",
    "\n",
    "model_space = SimpleSpace( #NodeSpace(\n",
    "         depth=depth, \n",
    "         nodes_per_layer=nodes_per_layer,\n",
    "         ops_per_node=ops_per_node, \n",
    "        #  poolOps_per_node=poolOps_per_node, \n",
    "        #  upsampleOps_per_node=upsampleOps_per_node\n",
    "        )\n",
    "\n",
    "# fast_dev_run=False\n",
    "\n",
    "config = RetiariiExeConfig(execution_engine='oneshot')\n",
    "experiment = RetiariiExperiment(model_space, evaluator=lightning, strategy=search_strategy)\n",
    "experiment.run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# stop experiment and clear cache\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m experiment\u001b[39m.\u001b[39mstop()\n\u001b[1;32m      3\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment' is not defined"
     ]
    }
   ],
   "source": [
    "# stop experiment and clear cache\n",
    "experiment.stop()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor 1 1 64 64\n",
    "# push the tensor through a nn.Conv2d(C_in, 64, kernel_size=3, padding=1) layer\n",
    "# then push the output through a nn.MaxPool2d(kernel_size=2, stride=2, padding=0) layer\n",
    "# print output shape\n",
    "\n",
    "x = torch.rand(1, 1, 64, 64)\n",
    "conv = torch.nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "out = conv(x)\n",
    "print(f'post in layer shape:   {out.shape}')\n",
    "out = pool(out)\n",
    "print(f'post pool layer shape: {out.shape}')\n",
    "\n",
    "def conv_2d(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "        nn.Conv2d(C_out, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation\n",
    "    )\n",
    "\n",
    "conv = conv_2d(64, 128, kernel_size=3, padding=1)\n",
    "out = conv(out)\n",
    "print(f'post conv layer shape: {out.shape}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random tensor 1 1 64 64\n",
    "# push the tensor through a nn.Conv2d(C_in, 64, kernel_size=3, padding=1) layer\n",
    "# then push the output through a nn.MaxPool2d(kernel_size=2, stride=2, padding=0) layer\n",
    "# print output shape\n",
    "\n",
    "x = torch.rand(1, 1, 64, 64)\n",
    "conv = torch.nn.Conv2d(1, 64, kernel_size=3, padding=1)\n",
    "pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "out = conv(x)\n",
    "out = pool(out)\n",
    "print(out.shape)\n",
    "\n",
    "def conv_2d(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "        nn.Conv2d(C_out, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation\n",
    "    )\n",
    "\n",
    "conv = conv_2d(64, 64, kernel_size=3, padding=1)\n",
    "out = conv(out)\n",
    "print(out.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "def conv_2d_with_attention(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        ChannelAttention(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "        nn.Conv2d(C_out, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        ChannelAttention(C_out),\n",
    "        nn.ReLU() if activation is None else activation\n",
    "    )\n",
    "\n",
    "x = torch.rand(1, 1, 64, 64)\n",
    "conv = conv_2d_with_attention(1, 64, kernel_size=3, padding=1)\n",
    "out = conv(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
