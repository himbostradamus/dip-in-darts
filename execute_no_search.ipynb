{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPUtil\n",
    "GPUs = GPUtil.getGPUs()\n",
    "for gpu in GPUs:\n",
    "  print(gpu.name, gpu.memoryTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_sgld import LightningEvalSearchSGLD, SingleImageDataset\n",
    "from darts.common_utils import *\n",
    "from darts.phantom import generate_phantom\n",
    "\n",
    "\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                       in_channels=1, out_channels=1, init_features=64, pretrained=False)\n",
    "\n",
    "num_iter=1\n",
    "total_iterations = 25000\n",
    "\n",
    "resolution = 6\n",
    "max_depth = resolution - 1\n",
    "phantom = generate_phantom(resolution=resolution)\n",
    "\n",
    "# Create the lightning module\n",
    "module = LightningEvalSearchSGLD(\n",
    "                phantom=phantom, \n",
    "                num_iter=num_iter,\n",
    "                lr=0.01, # note a smaller learning rate affecs the SGLD, so overfitting happens FASTER at LOWER learning rates (start with 0.01)\n",
    "                noise_type='gaussian', \n",
    "                noise_factor=0.09,\n",
    "                resolution=resolution,\n",
    "                burnin_iter=350,\n",
    "                model_cls=model\n",
    "                )\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            # callbacks=[module.checkpoint_callback],\n",
    "            max_epochs=total_iterations\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            )\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(phantom, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "lightning.fit(model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
