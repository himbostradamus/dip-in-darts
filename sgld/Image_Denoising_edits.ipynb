{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from models import *\n",
    "import torch\n",
    "import torch.optim\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from utils.denoising_utils import *\n",
    "import _pickle as cPickle\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# display images\n",
    "def np_plot(np_matrix, title):\n",
    "    plt.clf()\n",
    "    fig = plt.imshow(np_matrix.transpose(1, 2, 0), interpolation = 'nearest')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.pause(0.05) \n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/denoising/Dataset/image_Peppers512rgb.png'\n",
    "imsize =-1\n",
    "sigma = 25/255.\n",
    "img_pil = crop_image(get_image(fname, imsize)[0], d=32)\n",
    "img_np = pil_to_np(img_pil)                \n",
    "img_noisy_pil, img_noisy_np = get_noisy_image(img_np, sigma)\n",
    "np_plot(img_np, 'Natural image')\n",
    "np_plot(img_noisy_np, 'Noisy image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT = 'noise'\n",
    "pad = 'reflection'\n",
    "OPT_OVER = 'net' # optimize over the net parameters only\n",
    "reg_noise_std = 1./30.\n",
    "learning_rate = LR = 0.01\n",
    "exp_weight=0.99\n",
    "input_depth = 32 \n",
    "roll_back = True # to prevent numerical issues\n",
    "num_iter = 20000 # max iterations\n",
    "burnin_iter = 7000 # burn-in iteration for SGLD\n",
    "weight_decay = 5e-8\n",
    "show_every =  500\n",
    "mse = torch.nn.MSELoss().type(dtype) # loss\n",
    "img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgld_psnr_list = [] # psnr between sgld out and gt\n",
    "sgld_mean = 0\n",
    "roll_back = True # To solve the oscillation of model training \n",
    "last_net = None\n",
    "psrn_noisy_last = 0\n",
    "MCMC_iter = 50\n",
    "param_noise_sigma = 2\n",
    "\n",
    "sgld_mean_each = 0\n",
    "sgld_psnr_mean_list = [] # record the PSNR of avg after burn-in\n",
    "\n",
    "## SGLD\n",
    "def add_noise(model):\n",
    "    for n in [x for x in model.parameters() if len(x.size()) == 4]:\n",
    "        noise = torch.randn(n.size())*param_noise_sigma*learning_rate\n",
    "        noise = noise.type(dtype)\n",
    "        n.data = n.data + noise\n",
    "\n",
    "net2 = get_net(input_depth, 'skip', pad,\n",
    "            skip_n33d=128, \n",
    "            skip_n33u=128,\n",
    "            skip_n11=4,\n",
    "            num_scales=5,\n",
    "            upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "## Input random noise\n",
    "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0])).type(dtype).detach()\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "i = 0\n",
    "\n",
    "sample_count = 0\n",
    "\n",
    "def closure_sgld():\n",
    "    global i, net_input, sgld_mean, sample_count, psrn_noisy_last, last_net, sgld_mean_each\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    out = net2(net_input)\n",
    "    total_loss = mse(out, img_noisy_torch)\n",
    "    total_loss.backward()\n",
    "    out_np = out.detach().cpu().numpy()[0]\n",
    "\n",
    "    psrn_noisy = compare_psnr(img_noisy_np, out.detach().cpu().numpy()[0])\n",
    "    psrn_gt    = compare_psnr(img_np, out_np)\n",
    "\n",
    "    sgld_psnr_list.append(psrn_gt)\n",
    "\n",
    "    # Backtracking\n",
    "    if roll_back and i % show_every:\n",
    "        if psrn_noisy - psrn_noisy_last < -5: \n",
    "            print('Falling back to previous checkpoint.')\n",
    "            for new_param, net_param in zip(last_net, net2.parameters()):\n",
    "                net_param.detach().copy_(new_param.cuda())\n",
    "            return total_loss*0\n",
    "        else:\n",
    "            last_net = [x.detach().cpu() for x in net2.parameters()]\n",
    "            psrn_noisy_last = psrn_noisy\n",
    "\n",
    "    if i % show_every == 0:\n",
    "        np_plot(out.detach().cpu().numpy()[0], 'Iter: %d; gt %.2f' % (i, psrn_gt))\n",
    "    \n",
    "    if i > burnin_iter and np.mod(i, MCMC_iter) == 0:\n",
    "        sgld_mean += out_np\n",
    "        sample_count += 1.\n",
    "\n",
    "    if i > burnin_iter:\n",
    "        sgld_mean_each += out_np\n",
    "        sgld_mean_tmp = sgld_mean_each / (i - burnin_iter)\n",
    "        sgld_mean_psnr_each = compare_psnr(img_np, sgld_mean_tmp)\n",
    "        sgld_psnr_mean_list.append(sgld_mean_psnr_each) # record the PSNR of avg after burn-in\n",
    "        print('Iter: %d; psnr_gt %.2f; psnr_sgld %.2f' % (i, psrn_gt, sgld_mean_psnr_each))\n",
    "    else:\n",
    "        print('Iter: %d; psnr_gt %.2f; loss %.5f' % (i, psrn_gt, total_loss))\n",
    "    \n",
    "    if i == burnin_iter:\n",
    "        print('Burn-in done, start sampling')\n",
    "\n",
    "    i += 1\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "  ## Optimizing \n",
    "print('Starting optimization with SGLD')\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=LR, weight_decay = weight_decay)\n",
    "for j in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    closure_sgld()\n",
    "    optimizer.step()\n",
    "    add_noise(net2)\n",
    "\n",
    "sgld_mean = sgld_mean / sample_count\n",
    "sgld_mean_psnr = compare_psnr(img_np, sgld_mean)\n",
    "\n",
    "np_plot(sgld_mean.detach().cpu().numpy()[0], 'Iter: %d; gt %.2f' % (i, sgld_mean_psnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGLD Pytorch Lightning Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer, LightningModule\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim, tensor\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "# SGLD Pytorch Lightning Module\n",
    "class SingleImageDataset(Dataset):\n",
    "    def __init__(self, image, num_iter):\n",
    "        self.image = image\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_iter\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Always return the same image (and maybe a noise tensor or other information if necessary??)\n",
    "        return self.image\n",
    "\n",
    "class SGLD(LightningModule):\n",
    "    def __init__(self, \n",
    "        original_np,\n",
    "        noisy_np,\n",
    "        noisy_torch\n",
    "    ):\n",
    "        super().__init__()\n",
    "        print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "        print(f'DTYPE: {dtype}')\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        # iterators\n",
    "        self.burnin_iter=7000 # burn-in iteration for SGLD\n",
    "        self.show_every=500\n",
    "        self.num_iter=20000\n",
    "\n",
    "        # backtracking\n",
    "        self.psrn_noisy_last=0\n",
    "        self.last_net = None\n",
    "        self.roll_back = True # To solve the oscillation of model training \n",
    "\n",
    "        # SGLD Output Accumulation\n",
    "        self.sgld_mean=0\n",
    "        self.sgld_mean_each=0\n",
    "        self.sgld_psnr_list = [] # psnr between sgld out and gt\n",
    "        self.MCMC_iter=50\n",
    "        self.param_noise_sigma=2\n",
    "\n",
    "        # tinker with image input\n",
    "        self.img_np = original_np           \n",
    "        self.img_noisy_np = noisy_np\n",
    "        self.img_noisy_torch = noisy_torch\n",
    "        \n",
    "        # network input\n",
    "        self.input_depth = 32\n",
    "        self.model = get_net(\n",
    "                    self.input_depth, \n",
    "                    'skip', \n",
    "                    'reflection',\n",
    "                    skip_n33d=128, \n",
    "                    skip_n33u=128,\n",
    "                    skip_n11=4,\n",
    "                    num_scales=5,\n",
    "                    upsample_mode='bilinear'\n",
    "                ).type(self.dtype)\n",
    "        self.net_input = get_noise(self.input_depth, 'noise', (img_np.shape[-2:][1], img_np.shape[-2:][0])).type(self.dtype).detach()\n",
    "        self.net_input_saved = self.net_input.detach().clone()\n",
    "        self.noise = self.net_input.detach().clone()\n",
    "        \n",
    "        # closure\n",
    "        self.reg_noise_std = tensor(1./30.)\n",
    "        self.criteria = torch.nn.MSELoss().type(dtype) # loss\n",
    "\n",
    "        # optimizer\n",
    "        self.learning_rate = 0.01\n",
    "        self.weight_decay = 5e-8\n",
    "\n",
    "    ## SGLD\n",
    "    def add_noise(self, net):\n",
    "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "            noise = torch.randn(n.size())*self.param_noise_sigma*self.learning_rate\n",
    "            noise = noise.type(dtype)\n",
    "            n.data = n.data + noise\n",
    "\n",
    "    def forward(self, net_input_saved):\n",
    "        if self.reg_noise_std > 0:\n",
    "            self.net_input = self.net_input_saved + (self.noise.normal_() * self.reg_noise_std)\n",
    "            return self.model(self.net_input)\n",
    "        else:\n",
    "            return self.model(net_input_saved)\n",
    "\n",
    "    def closure_sgld(self):\n",
    "        out = self.forward(self.net_input)\n",
    "        total_loss = self.criteria(out, self.img_noisy_torch)\n",
    "        total_loss.backward()\n",
    "        out_np = out.detach().cpu().numpy()[0]\n",
    "\n",
    "        psrn_noisy = compare_psnr(self.img_noisy_np, out.detach().cpu().numpy()[0])\n",
    "        psrn_gt    = compare_psnr(self.img_np, out_np)\n",
    "\n",
    "        self.sgld_psnr_list.append(psrn_gt)\n",
    "\n",
    "        # Backtracking\n",
    "        if self.roll_back and self.i % self.show_every:\n",
    "            if psrn_noisy - self.psrn_noisy_last < -5: \n",
    "                print('Falling back to previous checkpoint.')\n",
    "                for new_param, net_param in zip(self.last_net, self.model.parameters()):\n",
    "                    net_param.detach().copy_(new_param.cuda())\n",
    "                return total_loss*0\n",
    "            else:\n",
    "                self.last_net = [x.detach().cpu() for x in model.parameters()]\n",
    "                self.psrn_noisy_last = psrn_noisy\n",
    "\n",
    "        if self.i % self.show_every == 0:\n",
    "            np_plot(out.detach().cpu().numpy()[0], 'Iter: %d; gt %.2f' % (self.i, psrn_gt))\n",
    "        \n",
    "        if self.i > self.burnin_iter and np.mod(self.i, self.MCMC_iter) == 0:\n",
    "            self.sgld_mean += out_np\n",
    "            self.sample_count += 1.\n",
    "\n",
    "        if self.i > self.burnin_iter:\n",
    "            self.sgld_mean_each += out_np\n",
    "            sgld_mean_tmp = self.sgld_mean_each / (self.i - self.burnin_iter)\n",
    "            self.sgld_mean_psnr_each = compare_psnr(self.img_np, self.sgld_mean_tmp)\n",
    "            self.sgld_psnr_mean_list.append(self.sgld_mean_psnr_each) # record the PSNR of avg after burn-in\n",
    "            print('Iter: %d; psnr_gt %.2f; psnr_sgld %.2f' % (self.i, psrn_gt, self.sgld_mean_psnr_each))\n",
    "        else:\n",
    "            print('Iter: %d; psnr_gt %.2f; loss %.5f' % (self.i, psrn_gt, total_loss))\n",
    "        \n",
    "        if self.i == self.burnin_iter:\n",
    "            print('Burn-in done, start sampling')\n",
    "\n",
    "        self.i += 1\n",
    "        return total_loss\n",
    "\n",
    "    def configure_optimizers(self) -> Optimizer:\n",
    "        \"\"\"\n",
    "        We are doing a manual implementation of the SGLD optimizer\n",
    "        There is a SGLD optimizer that can be found here:\n",
    "            - https://pysgmcmc.readthedocs.io/en/pytorch/_modules/pysgmcmc/optimizers/sgld.html\n",
    "            - Implementing this would greatly affect the training step\n",
    "                - But could it work?? :`( I couldn't figure it out\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        \"\"\"\n",
    "        Trick this puppy into thinking we have a dataloader\n",
    "        It's a single image for deep image priors\n",
    "        So we just need to return a dataloader with a single image\n",
    "        \"\"\"\n",
    "        dataset = SingleImageDataset(self.img_np, self.num_iter)\n",
    "        return DataLoader(dataset, batch_size=1)\n",
    "\n",
    "    def on_train_start(self) -> None:\n",
    "        \"\"\"\n",
    "        Move all tensors to the GPU to begin training\n",
    "        Initialize Iterators\n",
    "        Set Sail\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        self.net_input = self.net_input.to(self.device)\n",
    "        self.img_noisy_torch = self.img_noisy_torch.to(self.device)\n",
    "        self.reg_noise_std = self.reg_noise_std.to(self.device)\n",
    "\n",
    "        self.net_input_saved = self.net_input.clone().to(self.device)\n",
    "        self.noise = self.net_input.clone().to(self.device)\n",
    "        \n",
    "        # Initialize Iterations\n",
    "        self.i=0\n",
    "        self.sample_count=0\n",
    "\n",
    "        # bon voyage\n",
    "        print('Starting optimization with SGLD')\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int) -> Any:\n",
    "        \"\"\"\n",
    "        Oh the places you'll go\n",
    "        ---> Straight to error city calling this add_noise in the training step\n",
    "        ---> Consider using the on_train_batch_end hook? (each batch is only one iteration)\n",
    "        \"\"\"\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.zero_grad()\n",
    "        loss = self.closure_sgld()\n",
    "        optimizer.step()\n",
    "        self.add_noise(model)\n",
    "        return loss\n",
    "\n",
    "    def on_train_end(self) -> None:\n",
    "        \"\"\"\n",
    "        May all your dreams come true\n",
    "        \"\"\"\n",
    "        self.sgld_mean = self.sgld_mean / self.sample_count\n",
    "        np_plot(self.sgld_mean.detach().cpu().numpy()[0], 'Final after %d iterations' % (self.i))\n",
    "        \n",
    "\n",
    "\n",
    "def image_unpack(fname, imsize=-1, sigma=25/255):\n",
    "    dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "\n",
    "    img_pil = crop_image(get_image(fname, imsize)[0], d=32) \n",
    "    img_np = pil_to_np(img_pil)\n",
    "    \n",
    "    img_noisy_pil, img_noisy_np = get_noisy_image(img_np, sigma)\n",
    "    img_noisy_torch = np_to_torch(img_noisy_np).type(dtype)\n",
    "    \n",
    "    return {\n",
    "        'original_pil': img_pil,\n",
    "        'original_np': img_np,\n",
    "        'noisy_pil': img_noisy_pil, \n",
    "        'noisy_np': img_noisy_np,\n",
    "        'noisy_torch': img_noisy_torch\n",
    "    }\n",
    "\n",
    "\n",
    "# choose iterations\n",
    "num_iter = 20000 # max iterations\n",
    "\n",
    "# get image\n",
    "fname = 'data/denoising/Dataset/image_Peppers512rgb.png'\n",
    "img_dict = image_unpack(fname)\n",
    "original_pil = img_dict['original_pil']\n",
    "original_np = img_dict['original_np'] \n",
    "noisy_pil = img_dict['noisy_pil']\n",
    "noisy_np = img_dict['noisy_np']\n",
    "noisy_torch = img_dict['noisy_torch']\n",
    "\n",
    "\n",
    "# reference model\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor  \n",
    "model = get_net(\n",
    "                32, \n",
    "                'skip', \n",
    "                'reflection',\n",
    "                skip_n33d=128, \n",
    "                skip_n33u=128,\n",
    "                skip_n11=4,\n",
    "                num_scales=5,\n",
    "                upsample_mode='bilinear'\n",
    "            ).type(dtype)\n",
    "\n",
    "# Create the lightning module\n",
    "module = SGLD(\n",
    "        original_np=original_np,\n",
    "        noisy_np=noisy_np,\n",
    "        noisy_torch=noisy_torch)\n",
    "\n",
    "# Create a PyTorch Lightning trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=num_iter,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            checkpoint_callback=False\n",
    "            )\n",
    "\n",
    "# Initialize ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='./{lightning_logs}/{logger_name}/version_{version}/checkpoints/',\n",
    "    filename='{epoch}-{step}',\n",
    "    every_n_epochs=500,\n",
    "    save_top_k=1,\n",
    ")\n",
    "\n",
    "# Add the checkpoint callback to trainer\n",
    "trainer.callbacks.append(checkpoint_callback)\n",
    "            \n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "\n",
    "# Create the lighting object for evaluator\n",
    "train_loader = DataLoader(SingleImageDataset(noisy_np, num_iter=1), batch_size=1)\n",
    "val_loader = DataLoader(SingleImageDataset(noisy_np, num_iter=1), batch_size=1)\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "# Initialize TPU\n",
    "device = xm.xla_device()\n",
    "\n",
    "MCMC_iter = 50\n",
    "param_noise_sigma = 2\n",
    "\n",
    "# Initialize these as tensors on the TPU\n",
    "i = torch.tensor(0, device=device)\n",
    "sample_count = torch.tensor(0.0, device=device)\n",
    "sgld_mean = torch.zeros([1, *img_np.shape[1:]], dtype=torch.float32, device=device)\n",
    "sgld_mean_each = torch.zeros([1, *img_np.shape[1:]], dtype=torch.float32, device=device)\n",
    "\n",
    "## SGLD\n",
    "def add_noise(model):\n",
    "    for n in [x for x in model.parameters() if len(x.size()) == 4]:\n",
    "        noise = torch.randn(n.size())*param_noise_sigma*learning_rate\n",
    "        noise = noise.type(dtype)\n",
    "        n.data = n.data + noise\n",
    "\n",
    "net2 = get_net(input_depth, 'skip', pad,\n",
    "            skip_n33d=128, \n",
    "            skip_n33u=128,\n",
    "            skip_n11=4,\n",
    "            num_scales=5,\n",
    "            upsample_mode='bilinear').type(dtype)\n",
    "\n",
    "## Input random noise\n",
    "net_input = get_noise(input_depth, INPUT, (img_pil.size[1], img_pil.size[0])).type(dtype).detach()\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "def closure_sgld():\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    out = net2(net_input)\n",
    "    total_loss = mse(out, img_noisy_torch)\n",
    "    total_loss.backward()\n",
    "    out_np = out.detach().cpu().numpy()[0]\n",
    "    \n",
    "    if i > burnin_iter and i % MCMC_iter == 0:\n",
    "        sgld_mean += out_np\n",
    "        sample_count += 1.\n",
    "\n",
    "    if i > burnin_iter:\n",
    "        sgld_mean_each += out_np\n",
    "        sgld_mean_tmp = sgld_mean_each / (i - burnin_iter)\n",
    "\n",
    "    i += 1\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "  ## Optimizing \n",
    "print('Starting optimization with SGLD')\n",
    "optimizer = torch.optim.Adam(net2.parameters(), lr=LR, weight_decay = weight_decay)\n",
    "for j in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    closure_sgld()\n",
    "    optimizer.step()\n",
    "    add_noise(net2)\n",
    "\n",
    "sgld_mean /= sample_count\n",
    "sgld_mean_psnr = compare_psnr(img_np, sgld_mean)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(img_np.squeeze(), cmap='gray')\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(sgld_mean.squeeze(), cmap='gray')\n",
    "ax[1].set_title(\"Denoised Image\")\n",
    "ax[1].axis('off')\n",
    "\n",
    "ax[2].imshow(img_noisy_torch.detach().cpu().squeeze().numpy(), cmap='gray')\n",
    "ax[2].set_title(\"Noisy Image\")\n",
    "ax[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyModel:\n",
    "    def __init__(self, ...):  \n",
    "        self.i = torch.tensor(0, device=device)\n",
    "        self.sample_count = torch.tensor(0.0, device=device)\n",
    "        self.sgld_mean = torch.zeros([1, *img_np.shape[1:]], dtype=torch.float32, device=device)\n",
    "        self.sgld_mean_each = torch.zeros([1, *img_np.shape[1:]], dtype=torch.float32, device=device)\n",
    "        self.net = ...  # Initialize model\n",
    "        # Initialize other necessary attributes\n",
    "    \n",
    "    def closure_sgld(self):\n",
    "        if self.i > self.burnin_iter and self.i % self.MCMC_iter == 0:\n",
    "            self.sgld_mean += self.out.detach()\n",
    "            self.sample_count += 1.0\n",
    "\n",
    "        if self.i > self.burnin_iter:\n",
    "            self.sgld_mean_each += self.out.detach()\n",
    "            self.sgld_mean_tmp = self.sgld_mean_each / (self.i - self.burnin_iter)\n",
    "\n",
    "        self.i += 1\n",
    "        return self.total_loss\n",
    "\n",
    "\n",
    "# Initialize TPU\n",
    "device = xm.xla_device()\n",
    "\n",
    "# Initialize class-based model\n",
    "model = MyModel(...)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.net.parameters(), lr=LR, weight_decay = weight_decay)\n",
    "for j in range(num_iter):\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.closure_sgld()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    add_noise(net2) # net2 is the model in the previous example"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
