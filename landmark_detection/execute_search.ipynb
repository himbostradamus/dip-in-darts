{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from training import EvalLandmark\n",
    "import CERDataset\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "# mode settings for mode = 'pretrain2'\n",
    "mode = 'pretrain2'\n",
    "source_dir = 'TrainingImages2' # check\n",
    "source_name = 'image_'\n",
    "landmarks_dir = 'TrainingLabels1' # check\n",
    "landmarks_name = 'labels_'\n",
    "target_dir = 'DetectedLandmarks2' # check\n",
    "target_name = 'imageDetected_'\n",
    "params_name = '2pretrain_params.pt' # check\n",
    "train_loss_name = '2pretrain_train_loss.npy' #???\n",
    "val_loss_name = '2pretrain_val_loss.npy' #???\n",
    "loss_fig = '2loss_Pretraining.png' # check\n",
    "loss_file = '2loss.txt' # check\n",
    "\n",
    "# landmarks\n",
    "numOfLandmarks = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single run - no search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from cnn6 import CNN\n",
    "\n",
    "# mode settings for mode = 'pretrain2'\n",
    "mode = 'pretrain2'\n",
    "source_dir = 'TrainingImages2' # check\n",
    "source_name = 'image_'\n",
    "landmarks_dir = 'TrainingLabels1' # check\n",
    "landmarks_name = 'labels_'\n",
    "target_dir = 'DetectedLandmarks2' # check\n",
    "target_name = 'imageDetected_'\n",
    "params_name = '2pretrain_params.pt' # check\n",
    "train_loss_name = '2pretrain_train_loss.npy' #???\n",
    "val_loss_name = '2pretrain_val_loss.npy' #???\n",
    "loss_fig = '2loss_Pretraining.png' # check\n",
    "loss_file = '2loss.txt' # check\n",
    "\n",
    "# landmarks\n",
    "numOfLandmarks = 4\n",
    "\n",
    "# settings for pytorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "# tinker with weight and bias definitions here\n",
    "# new cnn6 design labels the layers slightly differently\n",
    "depth = 6\n",
    "new_state_dict = {}\n",
    "old_weights = torch.load(params_name,map_location=torch.device(device))\n",
    "for i in range(depth):  # Assuming depth is the number of convolutional layers.\n",
    "    new_state_dict[f\"convs.{i}.weight\"] = old_weights[f\"conv{i + 1}.weight\"]\n",
    "    new_state_dict[f\"convs.{i}.bias\"] = old_weights[f\"conv{i + 1}.bias\"]\n",
    "new_state_dict[\"fullyConnected.weight\"] = old_weights[\"fullConnected7.weight\"]\n",
    "new_state_dict[\"fullyConnected.bias\"] = old_weights[\"fullConnected7.bias\"]\n",
    "new_state_dict[\"output.weight\"] = old_weights[\"output.weight\"]\n",
    "new_state_dict[\"output.bias\"] = old_weights[\"output.bias\"]\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "# load and shuffle data and define train/test dataloader\n",
    "full_data = CERDataset.CERDataset(landmark_dir=landmarks_dir, image_dir=source_dir)\n",
    "train_data_size = int(0.72 * len(full_data))\n",
    "test_data_size = int(0.18 * len(full_data))\n",
    "valid_data_size = len(full_data) - train_data_size - test_data_size\n",
    "assert train_data_size + test_data_size + valid_data_size == len(full_data)\n",
    "train_data, test_data, valid_data = torch.utils.data.random_split(full_data,\n",
    "                                                                  [train_data_size, test_data_size, valid_data_size],\n",
    "                                                                  generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
    "\n",
    "module = EvalLandmark(mode=mode)\n",
    "\n",
    "\n",
    "# from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "# early_stop_callback = EarlyStopping(\n",
    "#             monitor=\"validation_loss\", \n",
    "#             min_delta=0.00, \n",
    "#             patience=200, \n",
    "#             verbose=False, \n",
    "#             mode=\"max\"\n",
    "#             )\n",
    "\n",
    "trainer = Trainer(\n",
    "            max_epochs=10000,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            enable_progress_bar=False,\n",
    "            # callbacks=[early_stop_callback],\n",
    "            )\n",
    "\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "lightning.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-trial search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MT specific imports\n",
    "from nni import trace\n",
    "import nni.retiarii.strategy as strategy\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "from trainingMT import EvalLandmarkMT\n",
    "from cnn6_space_mt import CNN_Space_MT\n",
    "\n",
    "\n",
    "\n",
    "# load and shuffle data and define train/test dataloader\n",
    "full_data = CERDataset.CERDataset(landmark_dir=landmarks_dir, image_dir=source_dir)\n",
    "train_data_size = int(0.72 * len(full_data))\n",
    "test_data_size = int(0.18 * len(full_data))\n",
    "valid_data_size = len(full_data) - train_data_size - test_data_size\n",
    "assert train_data_size + test_data_size + valid_data_size == len(full_data)\n",
    "train_data, test_data, valid_data = torch.utils.data.random_split(full_data,\n",
    "                                                                  [train_data_size, test_data_size, valid_data_size],\n",
    "                                                                  generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
    "\n",
    "# Create a Lightning Module\n",
    "module = EvalLandmarkMT(mode=mode)\n",
    "\n",
    "# Create a Search Space\n",
    "# this implementation gives flexibility in the depth of the encoder half of the network\n",
    "model_space = CNN_Space_MT(attention=True, depth=6)\n",
    "\n",
    "# configure the trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=1500,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            enable_progress_bar=False,\n",
    "            )\n",
    "\n",
    "# # Select a Search Strategy\n",
    "# https://nni.readthedocs.io/en/latest/nas/exploration_strategy.html\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "# search_strategy = strategy.TPE()\n",
    "# search_strategy = strategy.RegularizedEvolution(dedup=True)\n",
    "\n",
    "\n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "\n",
    "# Configure and run the experiment for multi-strategy\n",
    "experiment = RetiariiExperiment(model_space, lightning, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = f'MT_{search_strategy.__class__.__name__}_LandmarkDetection'\n",
    "\n",
    "# exp_config.max_trial_number = 250   # spawn {input} trials at most\n",
    "exp_config.trial_concurrency = 3  # will run {input} trials concurrently # on my machine each trial took up about 3260MiB of GPU memory so adjust accordingly\n",
    "# you can update both of these values in the web UI if you want to run more trials concurrently or run more trials in total\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "experiment.run(exp_config, 8889) # recommended in documentation was 8081 but 8889 worked ony my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_arch = experiment.export_top_models()\n",
    "\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# oneshot search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'_nni_symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m RetiariiExeConfig(execution_engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39moneshot\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     59\u001b[0m experiment \u001b[39m=\u001b[39m RetiariiExperiment(model_space, evaluator\u001b[39m=\u001b[39mlightning, strategy\u001b[39m=\u001b[39msearch_strategy)\n\u001b[0;32m---> 60\u001b[0m experiment\u001b[39m.\u001b[39;49mrun(config)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/experiment/pytorch.py:280\u001b[0m, in \u001b[0;36mRetiariiExperiment.run\u001b[0;34m(self, config, port, debug)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexecution_engine, OneshotEngineConfig) \\\n\u001b[1;32m    277\u001b[0m     \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexecution_engine, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexecution_engine \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39moneshot\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    278\u001b[0m     \u001b[39m# this is hacky, will be refactored when oneshot can run on training services\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     base_model_ir, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapplied_mutators \u001b[39m=\u001b[39m preprocess_model(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapplied_mutators, oneshot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 280\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mrun(base_model_ir, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapplied_mutators)\n\u001b[1;32m    281\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     ws_url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mws://localhost:\u001b[39m\u001b[39m{\u001b[39;00mport\u001b[39m}\u001b[39;00m\u001b[39m/tuner\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/strategy.py:83\u001b[0m, in \u001b[0;36mOneShotStrategy.run\u001b[0;34m(self, base_model, applied_mutators)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(base_model\u001b[39m.\u001b[39mevaluator, Lightning):\n\u001b[1;32m     81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mEvaluator needs to be a lightning evaluator to make one-shot strategy work.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattach_model(base_model)\n\u001b[1;32m     84\u001b[0m evaluator: Lightning \u001b[39m=\u001b[39m base_model\u001b[39m.\u001b[39mevaluator\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m evaluator\u001b[39m.\u001b[39mtrain_dataloaders \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m evaluator\u001b[39m.\u001b[39mval_dataloaders \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/strategy.py:69\u001b[0m, in \u001b[0;36mOneShotStrategy.attach_model\u001b[0;34m(self, base_model)\u001b[0m\n\u001b[1;32m     67\u001b[0m     evaluator_module\u001b[39m.\u001b[39mrunning_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39moneshot\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     68\u001b[0m     evaluator_module\u001b[39m.\u001b[39mset_model(base_model)\n\u001b[0;32m---> 69\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moneshot_module(evaluator_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moneshot_kwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/differentiable.py:104\u001b[0m, in \u001b[0;36mDartsLightningModule.__init__\u001b[0;34m(self, inner_module, mutation_hooks, arc_learning_rate, gradient_clip_val)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39marc_learning_rate \u001b[39m=\u001b[39m arc_learning_rate\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_clip_val \u001b[39m=\u001b[39m gradient_clip_val\n\u001b[0;32m--> 104\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(inner_module, mutation_hooks\u001b[39m=\u001b[39;49mmutation_hooks)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/base_lightning.py:266\u001b[0m, in \u001b[0;36mBaseOneShotLightningModule.__init__\u001b[0;34m(self, model, mutation_hooks)\u001b[0m\n\u001b[1;32m    263\u001b[0m mutation_hooks \u001b[39m=\u001b[39m (mutation_hooks \u001b[39mor\u001b[39;00m []) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mutation_hooks()\n\u001b[1;32m    265\u001b[0m \u001b[39m# traverse the model, calling hooks on every submodule\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnas_modules: \u001b[39mlist\u001b[39m[BaseSuperNetModule] \u001b[39m=\u001b[39m traverse_and_mutate_submodules(\n\u001b[1;32m    267\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, mutation_hooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutate_kwargs(), topdown\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/base_lightning.py:125\u001b[0m, in \u001b[0;36mtraverse_and_mutate_submodules\u001b[0;34m(root_module, hooks, mutate_kwargs, topdown)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[39mif\u001b[39;00m topdown:\n\u001b[1;32m    123\u001b[0m             apply(child)\n\u001b[0;32m--> 125\u001b[0m apply(root_module)\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m module_list\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/base_lightning.py:123\u001b[0m, in \u001b[0;36mtraverse_and_mutate_submodules.<locals>.apply\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m# pre-order DFS\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m topdown:\n\u001b[0;32m--> 123\u001b[0m     apply(child)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/base_lightning.py:90\u001b[0m, in \u001b[0;36mtraverse_and_mutate_submodules.<locals>.apply\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     87\u001b[0m mutate_result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m hooks:\n\u001b[0;32m---> 90\u001b[0m     hook_suggest \u001b[39m=\u001b[39m hook(child, name, memo, mutate_kwargs)\n\u001b[1;32m     92\u001b[0m     \u001b[39m# parse the mutate result\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(hook_suggest, \u001b[39mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/nas/oneshot/pytorch/base_lightning.py:151\u001b[0m, in \u001b[0;36mno_default_hook\u001b[0;34m(module, name, memo, mutate_kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(module, nas_nn\u001b[39m.\u001b[39mCell) \u001b[39mand\u001b[39;00m module\u001b[39m.\u001b[39mmerge_op \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    148\u001b[0m     \u001b[39m# need output_node_indices, which depends on super-net\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCell with merge_op `\u001b[39m\u001b[39m{\u001b[39;00mmodule\u001b[39m.\u001b[39mmerge_op\u001b[39m}\u001b[39;00m\u001b[39m` is not supported\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 151\u001b[0m \u001b[39mif\u001b[39;00m is_traceable(module):\n\u001b[1;32m    152\u001b[0m     \u001b[39m# check whether there is a value-choice in its arguments\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     has_valuechoice \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m chain(cast(\u001b[39mlist\u001b[39m, module\u001b[39m.\u001b[39mtrace_args), cast(\u001b[39mdict\u001b[39m, module\u001b[39m.\u001b[39mtrace_kwargs)\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/common/serializer.py:102\u001b[0m, in \u001b[0;36mis_traceable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_traceable\u001b[39m(obj: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m     94\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[39m    Check whether an object is a traceable instance or type.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39m    because the properties could be added **after** the instance has been created.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39mtrace_copy\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m--> 102\u001b[0m         \u001b[39mhasattr\u001b[39;49m(obj, \u001b[39m'\u001b[39;49m\u001b[39mtrace_symbol\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    103\u001b[0m         \u001b[39mhasattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39mtrace_args\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    104\u001b[0m         \u001b[39mhasattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39mtrace_kwargs\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/nni/common/serializer.py:203\u001b[0m, in \u001b[0;36m_make_class_traceable.<locals>.getter_factory.<locals>.<lambda>\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetter_factory\u001b[39m(x):\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39mself\u001b[39m: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__dict__\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m_nni_\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m x]\n",
      "\u001b[0;31mKeyError\u001b[0m: '_nni_symbol'"
     ]
    }
   ],
   "source": [
    "# oneshot search strategies evaluate concurrently by weight sharing\n",
    "# the search space needs to be restricted as the gpu memory gets full quickly in these methods\n",
    "# I recommend using a few different trials with:\n",
    "#     - short depth and wide range of convolution choices (kernals, dilation, depthwise, etc)\n",
    "#     - long depth and narrow range of convolution choices\n",
    "\n",
    "# the oneshot model will also need longer training time than a single trial\n",
    "\n",
    "# documentation: https://colab.research.google.com/github/microsoft/nni/blob/1037f585678280e9242ed1ad73bca7c00e7a0eab/docs/source/tutorials/darts.ipynb#scrollTo=FK0fC9fE5kr6\n",
    "\n",
    "import nni.retiarii.strategy as strategy\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "from cnn6_space_os import CNN_Space_OS\n",
    "from trainingOS import EvalLandmarkOS\n",
    "\n",
    "\n",
    "# load and shuffle data and define train/test dataloader\n",
    "full_data = CERDataset.CERDataset(landmark_dir=landmarks_dir, image_dir=source_dir)\n",
    "train_data_size = int(0.72 * len(full_data))\n",
    "test_data_size = int(0.18 * len(full_data))\n",
    "valid_data_size = len(full_data) - train_data_size - test_data_size\n",
    "assert train_data_size + test_data_size + valid_data_size == len(full_data)\n",
    "train_data, test_data, valid_data = torch.utils.data.random_split(full_data,\n",
    "                                                                  [train_data_size, test_data_size, valid_data_size],\n",
    "                                                                  generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
    "\n",
    "# Create a Lightning Module\n",
    "module = EvalLandmarkOS(mode=mode)\n",
    "\n",
    "# configure the trainer\n",
    "trainer = Trainer(\n",
    "            max_epochs=1500,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            enable_progress_bar=False,\n",
    "            )\n",
    "\n",
    "if not hasattr(trainer, 'optimizer_frequencies'):\n",
    "    trainer.optimizer_frequencies = []\n",
    "    \n",
    "lightning = Lightning(lightning_module=module, trainer=trainer, train_dataloaders=train_dataloader, val_dataloaders=valid_dataloader)\n",
    "\n",
    "# Select the Search Strategy\n",
    "search_strategy = strategy.DARTS()\n",
    "# search_strategy = strategy.DartsStrategy()\n",
    "# search_strategy = strategy.ENAS()\n",
    "# search_strategy = strategy.GumbelDARTS()\n",
    "# search_strategy = strategy.RandomOneShot()\n",
    "\n",
    "# Create a Search Space\n",
    "# this implementation gives flexibility in the depth of the encoder half of the network\n",
    "model_space = CNN_Space_OS(attention=False, depth=1)\n",
    "\n",
    "config = RetiariiExeConfig(execution_engine='oneshot')\n",
    "experiment = RetiariiExperiment(model_space, evaluator=lightning, strategy=search_strategy)\n",
    "experiment.run(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_arch = experiment.export_top_models()\n",
    "\n",
    "exported_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop experiment and clear cache\n",
    "experiment.stop()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
