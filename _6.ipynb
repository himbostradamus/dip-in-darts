{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import nni\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from nni.experiment import Experiment\n",
    "from nni.retiarii import model_wrapper\n",
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as skimage_psnr\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def psnr(image_true, image_test):\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    if torch.is_tensor(image_true):\n",
    "        image_true = image_true.detach().cpu().numpy()\n",
    "    if torch.is_tensor(image_test):\n",
    "        image_test = image_test.detach().cpu().numpy()\n",
    "    return skimage_psnr(image_true, image_test)\n",
    "\n",
    "def add_noise(img, noise_factor=0.5):\n",
    "    \"\"\"Add random noise to an image.\"\"\"\n",
    "    noise = torch.randn_like(img) * noise_factor\n",
    "    noisy_img = img + noise\n",
    "    return torch.clamp(noisy_img, 0., 1.)\n",
    "\n",
    "def deep_image_prior_denoising(model, noisy_img, clean_img, device, optimizer, iterations=250):\n",
    "    model.train()\n",
    "    for iteration in range(iterations):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(torch.randn(noisy_img.shape).to(device))\n",
    "        loss = nn.MSELoss()(output, noisy_img)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if iteration % 25 == 0:\n",
    "            # Calculate PSNR\n",
    "            with torch.no_grad():\n",
    "                denoised_output = model(noisy_img)\n",
    "                psnr_value = psnr(clean_img, denoised_output)\n",
    "            print('Iteration: {}\\tLoss: {:.6f}\\tPSNR: {:.6f} dB'.format(iteration, loss.item(), psnr_value))\n",
    "            nni.report_intermediate_result(psnr_value)\n",
    "    return output\n",
    "\n",
    "def evaluate_denoising(denoised_img, clean_img):\n",
    "    # We no longer need the model in an eval state or any forward pass here\n",
    "    # because the denoised image is already generated and passed to the function.\n",
    "    return psnr(clean_img, denoised_img)\n",
    "\n",
    "def main_evaluation(model_cls):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = model_cls().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    img, _ = dataset[0]  # Original clean image\n",
    "    noisy_img = add_noise(img).unsqueeze(0).to(device)  # Noisy version of image\n",
    "\n",
    "    # Denoise the image for a set number of iterations\n",
    "    denoised_img = deep_image_prior_denoising(model, noisy_img, img.unsqueeze(0).to(device), device, optimizer)\n",
    "\n",
    "    # Evaluate the PSNR of the denoised image\n",
    "    psnr_value = evaluate_denoising(denoised_img, img.unsqueeze(0).to(device))\n",
    "    print('PSNR: {:.6f} dB'.format(psnr_value))\n",
    "\n",
    "    # Report final PSNR to NNI\n",
    "    nni.report_final_result(psnr_value.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutions(nn.Module):\n",
    "    def __init__(self, out_channels, activations, convs1, convs2, layer_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.LayerChoice(convs1, label=f'{layer_name} - Step 1: Convolution 1')\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.act1 = nn.LayerChoice(activations, label=f'{layer_name} - Step 2: Activation 1')\n",
    "        \n",
    "        self.conv2 = nn.LayerChoice(convs2, label=f'{layer_name} - Step 3: Convolution 2')\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.act2 = nn.LayerChoice(activations, label=f'{layer_name} - Step 4: Activation 2')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, first=True):\n",
    "        layers = [\n",
    "            (\"Conv2d\", nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)),\n",
    "            (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        if not first:\n",
    "            layers.append((\"Depthwise\", nn.Conv2d(in_channels, out_channels, kernel_size=1)))\n",
    "        return OrderedDict(layers)\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, downsamples, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = nn.LayerChoice(downsamples,label=f'{layer_name} - Step 0: Downsampling Technique')\n",
    "        self.conv_layer = Convolutions(out_channels, \n",
    "                                       activations, \n",
    "                                       self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl),\n",
    "                                       self.get_conv_ordered_dict(out_channels, out_channels, ks, pd, dl, first=False), \n",
    "                                       layer_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, upsamples, layer_name):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.upsample = nn.LayerChoice(upsamples, label=f\"{layer_name} - Step 0: Upsampling Technique\")\n",
    "        self.conv_layer = Convolutions(out_channels, \n",
    "                                       activations, \n",
    "                                       self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl),\n",
    "                                       self.get_conv_ordered_dict(out_channels, out_channels, ks, pd, dl, first=False), \n",
    "                                       layer_name)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        ks = nn.ValueChoice([1, 3, 5, 7, 9], label=\"Kernel Size\")\n",
    "        dl = nn.ValueChoice([1, 2, 3, 4, 5], label=\"Dilation Rate\")\n",
    "        pd = (ks - 1) * dl // 2\n",
    "        # pdd = ks // 2\n",
    "\n",
    "        activations = OrderedDict([\n",
    "            (\"RelU\", nn.ReLU(inplace=True)),\n",
    "            (\"LeakyRelU\", nn.LeakyReLU(inplace=True)),\n",
    "            (\"Sigmoid\", nn.Sigmoid()),\n",
    "            (\"Selu\", nn.SELU(inplace=True)),\n",
    "            (\"PreLU\", nn.PReLU()),\n",
    "            (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "        ])\n",
    "\n",
    "        downsamples = OrderedDict([\n",
    "            (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "        ])\n",
    "\n",
    "        upsamples = OrderedDict([\n",
    "            (\"Nearest\", nn.Upsample(scale_factor=2,mode='nearest')),\n",
    "            (\"Bilinear\", nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True)),\n",
    "            (\"Bicubic\", nn.Upsample(scale_factor=2,mode='bicubic', align_corners=True))\n",
    "        ])\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.layer1_out_channels = 64\n",
    "        self.convs1 = self.get_conv_ordered_dict(in_channels, self.layer1_out_channels, ks, pd, dl)\n",
    "        self.convs2 = self.get_conv_ordered_dict(self.layer1_out_channels, self.layer1_out_channels, ks, pd, dl, first=False)\n",
    "        self.first = Convolutions(self.layer1_out_channels, activations, self.convs1, self.convs2, \"First Conv Layer\")\n",
    "\n",
    "        # Encoders\n",
    "        self.Encoder1 = EncoderBlock(64,   128, ks, pd, dl, activations, downsamples, \"Encoder 1\")\n",
    "        self.Encoder2 = EncoderBlock(128,  256, ks, pd, dl, activations, downsamples, \"Encoder 2\")\n",
    "        self.Encoder3 = EncoderBlock(256,  512, ks, pd, dl, activations, downsamples, \"Encoder 3\")\n",
    "        self.Encoder4 = EncoderBlock(512, 1024, ks, pd, dl, activations, downsamples, \"Encoder 4\")\n",
    "\n",
    "        # Decoders\n",
    "        self.Decoder1 = DecoderBlock(512*3, 512, ks, pd, dl, activations, upsamples, \"Decoder 1\")\n",
    "        self.Decoder2 = DecoderBlock(256*3,  256, ks, pd, dl, activations, upsamples, \"Decoder 2\")\n",
    "        self.Decoder3 = DecoderBlock(128*3,  128, ks, pd, dl, activations, upsamples, \"Decoder 3\")\n",
    "        self.Decoder4 = DecoderBlock(64*3,    64, ks, pd, dl, activations, upsamples, \"Decoder 4\")\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logger.info(\"Input: %s\", x.size())\n",
    "        \n",
    "        encoders = [self.first, self.Encoder1, self.Encoder2, self.Encoder3, self.Encoder4]\n",
    "        decoders = [self.Decoder1, self.Decoder2, self.Decoder3, self.Decoder4]\n",
    "        \n",
    "        # Variables to store intermediate values\n",
    "        encoder_outputs = []\n",
    "\n",
    "        # Encoder pass\n",
    "        for i, encoder in enumerate(encoders):\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            logger.info(f\"Encoder {i if i != 0 else 'Conv layer in'}: %s\", x.size())\n",
    "\n",
    "        # Decoder pass\n",
    "        for i, decoder in enumerate(decoders):\n",
    "            x = decoder(x, encoder_outputs[-(i+2)])\n",
    "            logger.info(f\"Decoder {4-i}: %s\", x.size())\n",
    "\n",
    "        x = self.out(x)\n",
    "        logger.info(\"Output: %s\", x.size())\n",
    "        return x\n",
    "    \n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, first=False):\n",
    "         layers = [\n",
    "                (\"Conv2d\", nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)),\n",
    "                (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                    nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                    nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, dilation=1)\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "         if not first:\n",
    "            layers.append((\"Depthwise\", nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0, dilation=1)))\n",
    "         return OrderedDict(layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutions(nn.Module):\n",
    "    def __init__(self, out_channels, activations, convs1, convs2, layer_name):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.LayerChoice(convs1, label=f'{layer_name} - Step 1: Convolution 1')\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.act1 = nn.LayerChoice(activations, label=f'{layer_name} - Step 2: Activation 1')\n",
    "        \n",
    "        self.conv2 = nn.LayerChoice(convs2, label=f'{layer_name} - Step 3: Convolution 2')\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.act2 = nn.LayerChoice(activations, label=f'{layer_name} - Step 4: Activation 2')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "    \n",
    "class BaseBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseBlock, self).__init__()\n",
    "\n",
    "    def get_conv_ordered_dict(self, in_channels, out_channels, ks, pd, dl, first=True):\n",
    "        layers = [\n",
    "            (\"Conv2d\", nn.Conv2d(in_channels, out_channels, kernel_size=ks, padding=pd, dilation=dl)),\n",
    "            (\"DepthwiseSeparable\", nn.Sequential(\n",
    "                nn.Conv2d(in_channels, in_channels, kernel_size=ks, padding=pd, dilation=dl, groups=in_channels),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        if not first:\n",
    "            layers.append((\"Depthwise\", nn.Conv2d(in_channels, out_channels, kernel_size=1)))\n",
    "        return OrderedDict(layers)\n",
    "\n",
    "    def crop_tensor(self, target_tensor, tensor):\n",
    "        target_size = target_tensor.size()[2]  # Assuming height and width are same\n",
    "        tensor_size = tensor.size()[2]\n",
    "        delta = tensor_size - target_size\n",
    "        delta = delta // 2\n",
    "        return tensor[:, :, delta:tensor_size-delta, delta:tensor_size-delta]\n",
    "\n",
    "class EncoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, downsamples, layer_name):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        \n",
    "        self.downsample = nn.LayerChoice(downsamples,label=f'{layer_name} - Step 0: Downsampling Technique')\n",
    "        self.conv_layer = Convolutions(out_channels, \n",
    "                                       activations, \n",
    "                                       self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl),\n",
    "                                       self.get_conv_ordered_dict(out_channels, out_channels, ks, pd, dl, first=False), \n",
    "                                       layer_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBlock(BaseBlock):\n",
    "    def __init__(self, in_channels, out_channels, ks, pd, dl, activations, upsamples, layer_name):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "\n",
    "        self.upsample = nn.LayerChoice(upsamples, label=f\"{layer_name} - Step 0: Upsampling Technique\")\n",
    "        self.conv_layer = Convolutions(out_channels, \n",
    "                                       activations, \n",
    "                                       self.get_conv_ordered_dict(in_channels, out_channels, ks, pd, dl),\n",
    "                                       self.get_conv_ordered_dict(out_channels, out_channels, ks, pd, dl, first=False), \n",
    "                                       layer_name)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        upsampled = self.upsample(x)\n",
    "        cropped = self.crop_tensor(upsampled, skip)\n",
    "        return self.conv_layer(torch.cat([cropped, upsampled], 1))\n",
    "\n",
    "@model_wrapper\n",
    "class SearchSpace(BaseBlock):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super().__init__()\n",
    "\n",
    "        network_depth = nn.ValueChoice([1, 2, 3, 4], label=\"Network Depth\")\n",
    "        # maybe can use max of depth to create a better label down in the decoder_block = ... line below\n",
    "\n",
    "        ks = nn.ValueChoice([1, 3, 5, 7, 9], label=\"Kernel Size\")\n",
    "        dl = nn.ValueChoice([1, 2, 3, 4, 5], label=\"Dilation Rate\")\n",
    "        pd = (ks - 1) * dl // 2\n",
    "\n",
    "        activations = OrderedDict([\n",
    "            (\"RelU\", nn.ReLU(inplace=True)),\n",
    "            (\"LeakyRelU\", nn.LeakyReLU(inplace=True)),\n",
    "            (\"Sigmoid\", nn.Sigmoid()),\n",
    "            (\"Selu\", nn.SELU(inplace=True)),\n",
    "            (\"PreLU\", nn.PReLU()),\n",
    "            (\"SiLU\", nn.SiLU(inplace=True)),\n",
    "        ])\n",
    "\n",
    "        downsamples = OrderedDict([\n",
    "            (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2)),\n",
    "            (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "        ])\n",
    "\n",
    "        upsamples = OrderedDict([\n",
    "            (\"Nearest\", nn.Upsample(scale_factor=2,mode='nearest')),\n",
    "            (\"Bilinear\", nn.Upsample(scale_factor=2,mode='bilinear', align_corners=True)),\n",
    "            (\"Bicubic\", nn.Upsample(scale_factor=2,mode='bicubic', align_corners=True))\n",
    "        ])\n",
    "\n",
    "        # Conv layer in\"\n",
    "        self.mid_channels = 64\n",
    "        self.convs1 = self.get_conv_ordered_dict(in_channels, self.mid_channels, ks, pd, dl)\n",
    "        self.convs2 = self.get_conv_ordered_dict(self.mid_channels, self.mid_channels, ks, pd, dl, first=False)\n",
    "        self.first = Convolutions(self.mid_channels, activations, self.convs1, self.convs2, \"First Conv Layer\")\n",
    "\n",
    "\n",
    "        # For Encoders:\n",
    "        encoder_block = lambda index: EncoderBlock(64*(2**index), 64*(2**(index+1)), ks, pd, dl, activations, downsamples, f\"Encoder {index+1}\")\n",
    "        self.encoders = nn.Repeat(encoder_block, network_depth)\n",
    "\n",
    "        # For Decoders:\n",
    "        decoder_block = lambda index: DecoderBlock(64*(2**(index))*3, 64*(2**index), ks, pd, dl, activations, upsamples, f\"Decoder {index+1}\")\n",
    "        self.decoders = nn.Repeat(decoder_block, network_depth)\n",
    "        self.decoders = self.decoders[::-1]\n",
    "\n",
    "        # Conv layer out\n",
    "        self.out = nn.Conv2d(64, out_channels, kernel_size=ks, padding=pd, dilation=dl)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logger.info(\"Input: %s\", x.size())\n",
    "        \n",
    "        # Variables to store intermediate values\n",
    "        encoder_outputs = []\n",
    "\n",
    "        # Start with the first conv layer\n",
    "        x = self.first(x)\n",
    "        encoder_outputs.append(x)\n",
    "        logger.info(f\"Initial Conv Layer: %s\", x.size())\n",
    "\n",
    "        # Encoder pass\n",
    "        for i, encoder in enumerate(self.encoders):\n",
    "            x = encoder(x)\n",
    "            encoder_outputs.append(x)\n",
    "            logger.info(f\"Encoder {i+1}: %s\", x.size())\n",
    "\n",
    "        # Decoder pass\n",
    "        for i, decoder in enumerate(self.decoders):\n",
    "            x = decoder(x, encoder_outputs[-(i+2)])\n",
    "            logger.info(f\"Decoder {len(self.decoders) - i}: %s\", x.size())\n",
    "\n",
    "        x = self.out(x)\n",
    "        logger.info(\"Output: %s\", x.size())\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search space\n",
    "model_space = SearchSpace()\n",
    "evaluator = FunctionalEvaluator(main_evaluation)\n",
    "\n",
    "# search strategy\n",
    "search_strategy = strategy.Random(dedup=True)\n",
    "\n",
    "# experiment\n",
    "exp = RetiariiExperiment(model_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.trial_code_directory = 'C:/Users/Public/Public_VS_Code/NAS_test'\n",
    "exp_config.experiment_working_directory = 'C:/Users/Public/nni-experiments'\n",
    "\n",
    "exp_config.max_trial_number = 50   # spawn 50 trials at most\n",
    "exp_config.trial_concurrency = 2  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1 # will run 1 trial(s) concurrently\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "\n",
    "# Execute\n",
    "exp.run(exp_config, 8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment.connect(8081)\n",
    "experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pub_ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
