{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m model \u001b[39m=\u001b[39m CNN()\n\u001b[1;32m     36\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 37\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39;49mload(params_name,map_location\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(device)))\n\u001b[1;32m     38\u001b[0m \u001b[39m# model.eval()\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[39m# load and shuffle data and define train/test dataloader\u001b[39;00m\n\u001b[1;32m     41\u001b[0m full_data \u001b[39m=\u001b[39m CERDataset\u001b[39m.\u001b[39mCERDataset(landmark_dir\u001b[39m=\u001b[39mlandmarks_dir, image_dir\u001b[39m=\u001b[39msource_dir)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/torch/serialization.py:600\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m     \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m     \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m     orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_reader(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    601\u001b[0m         \u001b[39mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n\u001b[1;32m    602\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m received a zip file that looks like a TorchScript archive\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    603\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m dispatching to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m (call \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch.jit.load\u001b[39m\u001b[39m'\u001b[39m\u001b[39m directly to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    604\u001b[0m                           \u001b[39m\"\u001b[39m\u001b[39m silence this warning)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/torch/serialization.py:242\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name_or_buffer) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     \u001b[39msuper\u001b[39m(_open_zipfile_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileReader(name_or_buffer))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from cnn6 import CNN\n",
    "from training import EvalLandmark\n",
    "import CERDataset\n",
    "\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, Trainer\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# mode settings for mode = 'pretrain2'\n",
    "mode = 'pretrain2'\n",
    "source_dir = 'TrainingImages2'\n",
    "source_name = 'image_'\n",
    "landmarks_dir = 'TrainingLabels1'\n",
    "landmarks_name = 'labels_'\n",
    "target_dir = 'DetectedLandmarks2'\n",
    "target_name = 'imageDetected_'\n",
    "params_name = '2pretrain_params.pt'\n",
    "train_loss_name = '2pretrain_train_loss.npy'\n",
    "val_loss_name = '2pretrain_val_loss.npy'\n",
    "loss_fig = '2loss_Pretraining.png'\n",
    "loss_file = '2loss.txt'\n",
    "\n",
    "# landmarks\n",
    "numOfLandmarks = 4\n",
    "\n",
    "# settings for pytorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(params_name,map_location=torch.device(device)))\n",
    "# model.eval()\n",
    "\n",
    "# load and shuffle data and define train/test dataloader\n",
    "full_data = CERDataset.CERDataset(landmark_dir=landmarks_dir, image_dir=source_dir)\n",
    "train_data_size = int(0.72 * len(full_data))\n",
    "test_data_size = int(0.18 * len(full_data))\n",
    "valid_data_size = len(full_data) - train_data_size - test_data_size\n",
    "assert train_data_size + test_data_size + valid_data_size == len(full_data)\n",
    "train_data, test_data, valid_data = torch.utils.data.random_split(full_data,\n",
    "                                                                  [train_data_size, test_data_size, valid_data_size],\n",
    "                                                                  generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=8, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=8, shuffle=False)\n",
    "\n",
    "module = EvalLandmark(mode=mode)\n",
    "early_stop_callback = EarlyStopping(\n",
    "            monitor=\"validation_loss\", \n",
    "            min_delta=0.00, \n",
    "            patience=200, \n",
    "            verbose=False, \n",
    "            mode=\"max\"\n",
    "            )\n",
    "trainer = Trainer(\n",
    "            max_epochs=10000,\n",
    "            fast_dev_run=False,\n",
    "            gpus=1,\n",
    "            callbacks=[early_stop_callback],\n",
    "            )\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
