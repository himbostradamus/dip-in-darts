{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/lightning/fabric/__init__.py:29: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning.fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/joe/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "/home/joe/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/lightning/pytorch/__init__.py:45: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning.pytorch')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/joe/.cache/pypoetry/virtualenvs/nas-test-OHy8kATa-py3.8/lib/python3.8/site-packages/pkg_resources/__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import nni\n",
    "import torch\n",
    "\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from nni import trace\n",
    "from nni.retiarii import model_wrapper, fixed_arch\n",
    "from nni.retiarii.nn.pytorch import Cell\n",
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "from nni.retiarii.strategy import DARTS as DartsStrategy\n",
    "from nni.retiarii.evaluator.pytorch import Lightning, LightningModule, Trainer\n",
    "from nni.retiarii.evaluator.pytorch.lightning import DataLoader\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.utilities.types import STEP_OUTPUT\n",
    "\n",
    "from torch import optim, tensor, zeros_like\n",
    "from typing import Any\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "input shape: torch.Size([1, 784, 128, 128])\n",
      "encoder layer 1 shape: torch.Size([1, 128, 128, 128])\n",
      "encoder layer 2 shape: torch.Size([1, 64, 128, 128])\n",
      "encoder layer 3 shape: torch.Size([1, 32, 128, 128])\n",
      "encoder layer 4 shape: torch.Size([1, 16, 128, 128])\n",
      "decoder layer 5 shape: torch.Size([1, 32, 128, 128])\n",
      "decoder layer 6 shape: torch.Size([1, 64, 128, 128])\n",
      "decoder layer 7 shape: torch.Size([1, 128, 128, 128])\n",
      "decoder layer 8 shape: torch.Size([1, 4, 128, 128])\n",
      "output: torch.Size([1, 4, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "def conv_2d(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_out, kernel_size=kernel_size, dilation=dilation, padding=padding, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "    )\n",
    "\n",
    "def depthwise_separable_conv(C_in, C_out, kernel_size=3, dilation=1, padding=1, activation=None):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(C_in, C_in, kernel_size=kernel_size, dilation=dilation, padding=padding, groups=C_in, bias=False),\n",
    "        nn.Conv2d(C_in, C_out, 1, bias=False),\n",
    "        nn.BatchNorm2d(C_out),\n",
    "        nn.ReLU() if activation is None else activation,\n",
    "    )\n",
    "\n",
    "def pools():\n",
    "    pool_dict = OrderedDict([\n",
    "        (\"MaxPool2d\", nn.MaxPool2d(kernel_size=2, stride=2, padding=0)),\n",
    "        # (\"AvgPool2d\", nn.AvgPool2d(kernel_size=2, stride=2, padding=0)),\n",
    "        # (\"DepthToSpace\", nn.PixelShuffle(2)),\n",
    "    ])\n",
    "    return pool_dict\n",
    "\n",
    "def upsamples():\n",
    "    upsample_dict = OrderedDict([\n",
    "        (\"Upsample_nearest\", nn.Upsample(scale_factor=2, mode='nearest')),\n",
    "        (\"Upsample_bilinear\", nn.Upsample(scale_factor=2, mode='bilinear')),\n",
    "\n",
    "    ])\n",
    "    return upsample_dict\n",
    "\n",
    "def convs(C_in, C_out):\n",
    "    # all padding should follow this formula:\n",
    "    # pd = (ks - 1) * dl // 2\n",
    "    conv_dict = OrderedDict([\n",
    "        \n",
    "        (\"conv2d_1x1_Relu\", conv_2d(C_in, C_out)),\n",
    "        # (\"conv2d_1x1_SiLU\", conv_2d(C_in, C_out, activation=nn.SiLU())),\n",
    "\n",
    "        # (\"conv2d_3x3_Relu\", conv_2d(C_in, C_out, kernel_size=3, padding=1)),\n",
    "        # (\"conv2d_3x3_SiLU\", conv_2d(C_in, C_out, kernel_size=3, padding=1, activation=nn.SiLU())),\n",
    "\n",
    "        # (\"conv2d_5x5_Relu\", conv_2d(C_in, C_out, kernel_size=5, padding=2)),\n",
    "        # (\"conv2d_5x5_SiLU\", conv_2d(C_in, C_out, kernel_size=5, padding=2, activation=nn.SiLU())),\n",
    "\n",
    "\n",
    "        (\"convDS_1x1_Relu\", depthwise_separable_conv(C_in, C_out)),\n",
    "        # (\"convDS_1x1_SiLU\", depthwise_separable_conv(C_in, C_out, activation=nn.SiLU())),\n",
    "\n",
    "        # (\"convDS_3x3_Relu\", depthwise_separable_conv(C_in, C_out, kernel_size=3, padding=1)),\n",
    "        # # (\"convDS_3x3_SiLU\", depthwise_separable_conv(C_in, C_out, kernel_size=3, padding=1, activation=nn.SiLU())),\n",
    "\n",
    "        # # (\"convDS_5x5_Relu\", depthwise_separable_conv(C_in, C_out, kernel_size=5, padding=2)),\n",
    "        # (\"convDS_5x5_SiLU\", depthwise_separable_conv(C_in, C_out, kernel_size=5, padding=2, activation=nn.SiLU())),\n",
    "    ])\n",
    "    return conv_dict\n",
    "\n",
    "@model_wrapper\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, depth=4):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.depth = depth\n",
    "            \n",
    "        self.max_mid_channels = 128\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.ModuleList()\n",
    "        self.encoder.append(Cell(convs(self.in_channels, self.max_mid_channels), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'encoder conv {1}'))\n",
    "\n",
    "        for i in range(self.depth-1):\n",
    "\n",
    "            next_in_channels = int(self.max_mid_channels*(2**-i))\n",
    "            next_out_channels = int(self.max_mid_channels*(2**-(i+1)))\n",
    "            \n",
    "            self.encoder.append(Cell(convs(next_in_channels, next_out_channels), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'encoder conv {i+2}'))\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.ModuleList()\n",
    "        for i in range(self.depth-2,-1,-1):\n",
    "            \n",
    "            next_in_channels = int(self.max_mid_channels*(2**-(i+1)))\n",
    "            next_out_channels = int(self.max_mid_channels*(2**-i))\n",
    "\n",
    "            self.decoder.append(Cell(convs(next_in_channels, next_out_channels), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'decoder conv {i+1}'))\n",
    "\n",
    "        self.decoder.append(Cell(convs(self.max_mid_channels, self.out_channels), num_nodes=1, num_ops_per_node=1, num_predecessors=1, label=f'decoder conv {depth}'))\n",
    "\n",
    "    def forward(self,x):\n",
    "        \n",
    "\n",
    "        for i in range(self.depth):\n",
    "            x = self.encoder[i](x)\n",
    "        \n",
    "        for i in range(self.depth):\n",
    "            x = self.decoder[i](x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def test(self):\n",
    "\n",
    "        x = torch.randn(1,self.in_channels,128,128)\n",
    "        y = self.forward(x)\n",
    "        print(f'output: {y.shape}')\n",
    "\n",
    "model = Autoencoder(in_channels=784, out_channels=4, depth=4)\n",
    "\n",
    "model.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas-test-OHy8kATa-py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
